{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import scipy.io as sio\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "import datetime\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gazeData(data.Dataset):\n",
    "    def __init__(self, dataset, imSize=(224,224)):\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.imSize = imSize\n",
    "        \n",
    "        self.transformImg = transforms.Compose([transforms.Resize(self.imSize)\n",
    "                                                ,transforms.ToTensor(),\n",
    "                                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "        self.classLabel = [0]*16\n",
    "#         self.transformPoint = transforms.Compose([\n",
    "#             transforms.ToTensor()\n",
    "#         ])\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         index = self.indices[index]\n",
    "\n",
    "        filePath = self.dataset['file'][index]\n",
    "        image = Image.open(filePath).convert('RGB')\n",
    "        image = self.transformImg(image)   \n",
    "\n",
    "        labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        labels[self.dataset['location'][index]] = 1\n",
    "        labels = torch.FloatTensor(labels)\n",
    "        sample = {'image': image, 'labels': labels}\n",
    "        \n",
    "        \n",
    "        return sample\n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "__all__ = ['ResNet', 'resnet50']\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=16, include_top=True):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.include_top = include_top\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        if not self.include_top:\n",
    "            return x\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vggface(pretrained=False, **kwargs):\n",
    "    \"\"\"VGGFace model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns pre-trained model \n",
    "    \"\"\"\n",
    "    model = VggFace(**kwargs)\n",
    "    if pretrained:\n",
    "        state = torch.utils.model_zoo.load_url(MODEL_URL)\n",
    "        model.load_state_dict(state)\n",
    "    return model\n",
    "\n",
    "\n",
    "class VggFace(torch.nn.Module):\n",
    "    def __init__(self, classes=16):\n",
    "        \"\"\"VGGFace model.\n",
    "        Face recognition network.  It takes as input a Bx3x224x224\n",
    "        batch of face images and gives as output a BxC score vector\n",
    "        (C is the number of identities).\n",
    "        Input images need to be scaled in the 0-1 range and then \n",
    "        normalized with respect to the mean RGB used during training.\n",
    "        Args:\n",
    "            classes (int): number of identities recognized by the\n",
    "            network\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv1 = _ConvBlock(3, 64, 64)\n",
    "        self.conv2 = _ConvBlock(64, 128, 128)\n",
    "        self.conv3 = _ConvBlock(128, 256, 256, 256)\n",
    "        self.conv4 = _ConvBlock(256, 512, 512, 512)\n",
    "        self.conv5 = _ConvBlock(512, 512, 512, 512)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.fc1 = torch.nn.Linear(7 * 7 * 512, 4096)\n",
    "        self.fc2 = torch.nn.Linear(4096, 4096)\n",
    "        self.fc3 = torch.nn.Linear(4096, classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class _ConvBlock(torch.nn.Module):\n",
    "    \"\"\"A Convolutional block.\"\"\"\n",
    "\n",
    "    def __init__(self, *units):\n",
    "        \"\"\"Create a block with len(units) - 1 convolutions.\n",
    "        convolution number i transforms the number of channels from \n",
    "        units[i - 1] to units[i] channels.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList([\n",
    "            torch.nn.Conv2d(in_, out, 3, 1, 1)\n",
    "            for in_, out in zip(units[:-1], units[1:])\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Each convolution is followed by a ReLU, then the block is\n",
    "        # concluded by a max pooling.\n",
    "        for c in self.convs:\n",
    "            x = F.relu(c(x))\n",
    "        return F.max_pool2d(x, 2, 2, 0, ceil_mode=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, planes, compress_rate):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(planes, planes // compress_rate, kernel_size=1, stride=1, bias=True)\n",
    "        self.conv2 = nn.Conv2d(planes // compress_rate, planes, kernel_size=1, stride=1, bias=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = F.avg_pool2d(module_input, kernel_size=module_input.size(2))\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        # SENet\n",
    "        compress_rate = 16\n",
    "        # self.se_block = SEModule(planes * 4, compress_rate)  # this is not used.\n",
    "        self.conv4 = nn.Conv2d(planes * 4, planes * 4 // compress_rate, kernel_size=1, stride=1, bias=True)\n",
    "        self.conv5 = nn.Conv2d(planes * 4 // compress_rate, planes * 4, kernel_size=1, stride=1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "\n",
    "        ## senet\n",
    "        out2 = F.avg_pool2d(out, kernel_size=out.size(2))\n",
    "        out2 = self.conv4(out2)\n",
    "        out2 = self.relu(out2)\n",
    "        out2 = self.conv5(out2)\n",
    "        out2 = self.sigmoid(out2)\n",
    "        # out2 = self.se_block.forward(out)  # not used\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = out2 * out + residual\n",
    "        # out = out2 + residual  # not used\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SENet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=16, include_top=True):\n",
    "        self.inplanes = 64\n",
    "        super(SENet, self).__init__()\n",
    "        self.include_top = include_top\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        if not self.include_top:\n",
    "            return x\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def senet50(**kwargs):\n",
    "    \"\"\"Constructs a SENet-50 model.\n",
    "    \"\"\"\n",
    "    model = SENet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpointClass.pth.tar'):\n",
    "    CHECKPOINTS_PATH = './gazeClassCheckpoint'\n",
    "    if not os.path.isdir(CHECKPOINTS_PATH):\n",
    "        os.makedirs(CHECKPOINTS_PATH, 0o777)\n",
    "    bestFilename = os.path.join(CHECKPOINTS_PATH, 'best_' + filename)\n",
    "    filename = os.path.join(CHECKPOINTS_PATH, filename)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, bestFilename)\n",
    "        \n",
    "def load_checkpoint(filename='./gazeClassCheckpoint/checkpointClass.pth.tar'):\n",
    "    print(filename)\n",
    "    if not os.path.isfile(filename):\n",
    "        return None\n",
    "    state = torch.load(filename)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = 0.0001 * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.state_dict()['param_groups']:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = 16\n",
    "epochs = 25\n",
    "batch_size = 64\n",
    "weight_decay = 1e-4\n",
    "best_loss = 1000\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gaze = pd.read_csv('gazeClassData.csv')\n",
    "df_gaze =df_gaze.drop(['index'],axis=1)\n",
    "\n",
    "df_train=df_gaze.sample(frac=0.9,random_state=100) \n",
    "df_tmp= df_gaze.drop(df_train.index)\n",
    "\n",
    "df_train.reset_index(inplace=True)\n",
    "df_tmp.reset_index(inplace=True)\n",
    "\n",
    "df_val = df_tmp.sample(frac=0.5, random_state = 100)\n",
    "df_test = df_tmp.drop(df_val.index)\n",
    "\n",
    "df_val.reset_index(inplace=True)\n",
    "df_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>location</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>438573</td>\n",
       "      <td>2</td>\n",
       "      <td>./data/01849/frames/00743.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>703392</td>\n",
       "      <td>12</td>\n",
       "      <td>./data/02945/frames/00833.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158947</td>\n",
       "      <td>11</td>\n",
       "      <td>./data/00831/frames/00307.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>779797</td>\n",
       "      <td>15</td>\n",
       "      <td>./data/03312/frames/00838.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>587944</td>\n",
       "      <td>15</td>\n",
       "      <td>./data/02416/frames/00086.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  location                           file\n",
       "0  438573         2  ./data/01849/frames/00743.jpg\n",
       "1  703392        12  ./data/02945/frames/00833.jpg\n",
       "2  158947        11  ./data/00831/frames/00307.jpg\n",
       "3  779797        15  ./data/03312/frames/00838.jpg\n",
       "4  587944        15  ./data/02416/frames/00086.jpg"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 737485 val 40972 test 40971\n"
     ]
    }
   ],
   "source": [
    "print('train',len(df_train),'val',len(df_val),'test',len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = gazeData(dataset=df_train)\n",
    "dataVal = gazeData(dataset=df_val)\n",
    "dataTest = gazeData(dataset=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataTrain,\n",
    "        batch_size=batch_size, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        dataVal,\n",
    "        batch_size=batch_size, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        dataTest,\n",
    "        batch_size=1, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = resnet50()\n",
    "model = senet50()\n",
    "# model =vggface()\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.cuda()\n",
    "cudnn.benchmark = True   \n",
    "criterion = nn.MSELoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./gazeClassCheckpoint/checkpointClass.pth.tar\n",
      "Loading checkpoint for epoch 00002 with loss 0.00010 (which is the mean squared error not the actual linear error)...\n"
     ]
    }
   ],
   "source": [
    "epoch =0\n",
    "saved = load_checkpoint()\n",
    "if saved:\n",
    "    print('Loading checkpoint for epoch %05d with loss %.5f (which is the mean squared error not the actual linear error)...' % (saved['epoch'], saved['best_prec1']))\n",
    "    state = saved['state_dict']\n",
    "    try:\n",
    "        model.module.load_state_dict(state)\n",
    "    except:\n",
    "        model.load_state_dict(state)\n",
    "    epoch = saved['epoch']\n",
    "    best_loss = saved['best_prec1']\n",
    "else:\n",
    "    print('Warning: Could not read checkpoint!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion,optimizer, epoch):\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "    running_loss = 0\n",
    "    for i,sample in enumerate(train_loader):\n",
    "        frame, locationClass= sample['image'],sample['labels']\n",
    "\n",
    "        locationClass = locationClass.cuda()\n",
    "        frame = frame.cuda()\n",
    "        locationClass = torch.autograd.Variable(locationClass, requires_grad = True)\n",
    "        frame = torch.autograd.Variable(frame, requires_grad = True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(frame)\n",
    "        \n",
    "        loss = criterion(output, locationClass)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 통계를 출력합니다.\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 0:    # print every 2000 mini-batches\n",
    "            print('Train [%d, %d / %d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1,len(train_loader), running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "            print(str(datetime.datetime.now().time()))\n",
    "\n",
    "def validate(val_loader, model, criterion,optimizer, epoch) :\n",
    "\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "    val_loss = 0\n",
    "    for i,sample in enumerate(val_loader):\n",
    "        frame, locationClass= sample['image'],sample['labels']\n",
    "\n",
    "        locationClass = locationClass.cuda()\n",
    "        frame = frame.cuda()\n",
    "        locationClass = torch.autograd.Variable(locationClass, requires_grad = True)\n",
    "        frame = torch.autograd.Variable(frame, requires_grad = True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(frame)\n",
    "        \n",
    "        loss = criterion(output, locationClass)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        if i % 200 == 0:   \n",
    "            print('Validate [%d, %5d / %5d ] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1,len(val_loader) , val_loss / (i+1)))\n",
    "            print(str(datetime.datetime.now().time()))\n",
    "        return val_loss/len(val_loader)\n",
    "    \n",
    "def TestData(test_loader, model) :\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i,sample in enumerate(test_loader):\n",
    "        frame, locationClass= sample['image'],sample['labels']\n",
    "        locationClass = locationClass.cuda()\n",
    "        frame = frame.cuda()\n",
    "        locationClass = torch.autograd.Variable(locationClass, requires_grad = True)\n",
    "        frame = torch.autograd.Variable(frame, requires_grad = True)\n",
    "        \n",
    "        output = model(frame)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += locationClass.size(0)\n",
    "        correct += (predicted == locationClass).sum().item()\n",
    "        \n",
    "    print('Test set: Accuracy: {:.2f}%'.format(100. * correct / len(test_loader.dataset)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH > 2\n",
      "Train [3, 1 / 11524] loss: 0.000\n",
      "13:01:06.717224\n",
      "Train [3, 201 / 11524] loss: 0.062\n",
      "13:01:54.701258\n",
      "Train [3, 401 / 11524] loss: 0.062\n",
      "13:02:43.391670\n",
      "Train [3, 601 / 11524] loss: 0.062\n",
      "13:03:32.534243\n",
      "Train [3, 801 / 11524] loss: 0.062\n",
      "13:04:21.947116\n",
      "Train [3, 1001 / 11524] loss: 0.062\n",
      "13:05:11.159270\n",
      "Train [3, 1201 / 11524] loss: 0.062\n",
      "13:06:00.626293\n",
      "Train [3, 1401 / 11524] loss: 0.062\n",
      "13:06:50.009443\n",
      "Train [3, 1601 / 11524] loss: 0.062\n",
      "13:07:39.480730\n",
      "Train [3, 1801 / 11524] loss: 0.062\n",
      "13:08:28.683464\n",
      "Train [3, 2001 / 11524] loss: 0.062\n",
      "13:09:18.034103\n",
      "Train [3, 2201 / 11524] loss: 0.062\n",
      "13:10:07.441532\n",
      "Train [3, 2401 / 11524] loss: 0.062\n",
      "13:10:56.788837\n",
      "Train [3, 2601 / 11524] loss: 0.062\n",
      "13:11:45.948661\n",
      "Train [3, 2801 / 11524] loss: 0.062\n",
      "13:12:35.222827\n",
      "Train [3, 3001 / 11524] loss: 0.062\n",
      "13:13:24.365785\n",
      "Train [3, 3201 / 11524] loss: 0.062\n",
      "13:14:13.760509\n",
      "Train [3, 3401 / 11524] loss: 0.062\n",
      "13:15:03.053508\n",
      "Train [3, 3601 / 11524] loss: 0.062\n",
      "13:15:52.175341\n",
      "Train [3, 3801 / 11524] loss: 0.062\n",
      "13:16:41.444133\n",
      "Train [3, 4001 / 11524] loss: 0.062\n",
      "13:17:30.689134\n",
      "Train [3, 4201 / 11524] loss: 0.062\n",
      "13:18:19.843528\n",
      "Train [3, 4401 / 11524] loss: 0.062\n",
      "13:19:09.112778\n",
      "Train [3, 4601 / 11524] loss: 0.062\n",
      "13:19:58.316206\n",
      "Train [3, 4801 / 11524] loss: 0.062\n",
      "13:20:47.537055\n",
      "Train [3, 5001 / 11524] loss: 0.062\n",
      "13:21:36.680518\n",
      "Train [3, 5201 / 11524] loss: 0.062\n",
      "13:22:25.884178\n",
      "Train [3, 5401 / 11524] loss: 0.062\n",
      "13:23:15.147311\n",
      "Train [3, 5601 / 11524] loss: 0.062\n",
      "13:24:04.328729\n",
      "Train [3, 5801 / 11524] loss: 0.062\n",
      "13:24:53.654425\n",
      "Train [3, 6001 / 11524] loss: 0.062\n",
      "13:25:42.916855\n",
      "Train [3, 6201 / 11524] loss: 0.062\n",
      "13:26:32.154747\n",
      "Train [3, 6401 / 11524] loss: 0.062\n",
      "13:27:21.503996\n",
      "Train [3, 6601 / 11524] loss: 0.062\n",
      "13:28:10.748267\n",
      "Train [3, 6801 / 11524] loss: 0.062\n",
      "13:28:59.920294\n",
      "Train [3, 7001 / 11524] loss: 0.062\n",
      "13:29:49.101247\n",
      "Train [3, 7201 / 11524] loss: 0.062\n",
      "13:30:38.352483\n",
      "Train [3, 7401 / 11524] loss: 0.062\n",
      "13:31:27.569692\n",
      "Train [3, 7601 / 11524] loss: 0.062\n",
      "13:32:16.762376\n",
      "Train [3, 7801 / 11524] loss: 0.062\n",
      "13:33:06.026466\n",
      "Train [3, 8001 / 11524] loss: 0.062\n",
      "13:33:55.158846\n",
      "Train [3, 8201 / 11524] loss: 0.062\n",
      "13:34:44.295391\n",
      "Train [3, 8401 / 11524] loss: 0.062\n",
      "13:35:33.507235\n",
      "Train [3, 8601 / 11524] loss: 0.062\n",
      "13:36:22.770015\n",
      "Train [3, 8801 / 11524] loss: 0.062\n",
      "13:37:12.026325\n",
      "Train [3, 9001 / 11524] loss: 0.062\n",
      "13:38:01.110350\n",
      "Train [3, 9201 / 11524] loss: 0.062\n",
      "13:38:50.400422\n",
      "Train [3, 9401 / 11524] loss: 0.062\n",
      "13:39:39.583068\n",
      "Train [3, 9601 / 11524] loss: 0.062\n",
      "13:40:28.779033\n",
      "Train [3, 9801 / 11524] loss: 0.062\n",
      "13:41:17.940506\n",
      "Train [3, 10001 / 11524] loss: 0.062\n",
      "13:42:07.131451\n",
      "Train [3, 10201 / 11524] loss: 0.062\n",
      "13:42:56.222430\n",
      "Train [3, 10401 / 11524] loss: 0.062\n",
      "13:43:45.478267\n",
      "Train [3, 10601 / 11524] loss: 0.062\n",
      "13:44:34.597414\n",
      "Train [3, 10801 / 11524] loss: 0.062\n",
      "13:45:23.825978\n",
      "Train [3, 11001 / 11524] loss: 0.062\n",
      "13:46:13.017213\n",
      "Train [3, 11201 / 11524] loss: 0.062\n",
      "13:47:02.251548\n",
      "Train [3, 11401 / 11524] loss: 0.062\n",
      "13:47:51.392593\n",
      "Validate [3,     1 /   641 ] loss: 0.062\n",
      "13:48:25.002403\n",
      "Test set: Accuracy: 48.54%\n",
      "Train [4, 1 / 11524] loss: 0.000\n",
      "14:04:02.631721\n",
      "Train [4, 201 / 11524] loss: 0.062\n",
      "14:04:51.609769\n",
      "Train [4, 401 / 11524] loss: 0.062\n",
      "14:05:40.535555\n",
      "Train [4, 601 / 11524] loss: 0.062\n",
      "14:06:29.686232\n",
      "Train [4, 801 / 11524] loss: 0.062\n",
      "14:07:19.073015\n",
      "Train [4, 1001 / 11524] loss: 0.062\n",
      "14:08:08.562136\n",
      "Train [4, 1201 / 11524] loss: 0.062\n",
      "14:08:57.811338\n",
      "Train [4, 1401 / 11524] loss: 0.062\n",
      "14:09:47.160316\n",
      "Train [4, 1601 / 11524] loss: 0.062\n",
      "14:10:36.540221\n",
      "Train [4, 1801 / 11524] loss: 0.062\n",
      "14:11:26.002855\n",
      "Train [4, 2001 / 11524] loss: 0.062\n",
      "14:12:15.244646\n",
      "Train [4, 2201 / 11524] loss: 0.062\n",
      "14:13:04.460438\n",
      "Train [4, 2401 / 11524] loss: 0.062\n",
      "14:13:53.757048\n",
      "Train [4, 2601 / 11524] loss: 0.062\n",
      "14:14:42.800917\n",
      "Train [4, 2801 / 11524] loss: 0.062\n",
      "14:15:32.008934\n",
      "Train [4, 3001 / 11524] loss: 0.062\n",
      "14:16:21.179750\n",
      "Train [4, 3201 / 11524] loss: 0.062\n",
      "14:17:10.414948\n",
      "Train [4, 3401 / 11524] loss: 0.062\n",
      "14:17:59.490299\n",
      "Train [4, 3601 / 11524] loss: 0.062\n",
      "14:18:48.694789\n",
      "Train [4, 3801 / 11524] loss: 0.062\n",
      "14:19:37.903183\n",
      "Train [4, 4001 / 11524] loss: 0.062\n",
      "14:20:27.054771\n",
      "Train [4, 4201 / 11524] loss: 0.062\n",
      "14:21:16.150362\n",
      "Train [4, 4401 / 11524] loss: 0.062\n",
      "14:22:05.165083\n",
      "Train [4, 4601 / 11524] loss: 0.062\n",
      "14:22:54.274614\n",
      "Train [4, 4801 / 11524] loss: 0.062\n",
      "14:23:43.576379\n",
      "Train [4, 5001 / 11524] loss: 0.062\n",
      "14:24:32.717830\n",
      "Train [4, 5201 / 11524] loss: 0.062\n",
      "14:25:21.849905\n",
      "Train [4, 5401 / 11524] loss: 0.062\n",
      "14:26:10.941001\n",
      "Train [4, 5601 / 11524] loss: 0.062\n",
      "14:27:00.114565\n",
      "Train [4, 5801 / 11524] loss: 0.062\n",
      "14:27:49.185734\n",
      "Train [4, 6001 / 11524] loss: 0.062\n",
      "14:28:38.333692\n",
      "Train [4, 6201 / 11524] loss: 0.062\n",
      "14:29:27.549632\n",
      "Train [4, 6401 / 11524] loss: 0.062\n",
      "14:30:16.754641\n",
      "Train [4, 6601 / 11524] loss: 0.062\n",
      "14:31:05.786975\n",
      "Train [4, 6801 / 11524] loss: 0.062\n",
      "14:31:55.160052\n",
      "Train [4, 7001 / 11524] loss: 0.062\n",
      "14:32:44.326154\n",
      "Train [4, 7201 / 11524] loss: 0.062\n",
      "14:33:33.424806\n",
      "Train [4, 7401 / 11524] loss: 0.062\n",
      "14:34:22.552198\n",
      "Train [4, 7601 / 11524] loss: 0.062\n",
      "14:35:11.641495\n",
      "Train [4, 7801 / 11524] loss: 0.062\n",
      "14:36:00.758779\n",
      "Train [4, 8001 / 11524] loss: 0.062\n",
      "14:36:49.992762\n",
      "Train [4, 8201 / 11524] loss: 0.062\n",
      "14:37:39.042797\n",
      "Train [4, 8401 / 11524] loss: 0.062\n",
      "14:38:28.181242\n",
      "Train [4, 8601 / 11524] loss: 0.062\n",
      "14:39:17.411463\n",
      "Train [4, 8801 / 11524] loss: 0.062\n",
      "14:40:06.534273\n",
      "Train [4, 9001 / 11524] loss: 0.062\n",
      "14:40:55.707013\n",
      "Train [4, 9201 / 11524] loss: 0.062\n",
      "14:41:44.811803\n",
      "Train [4, 9401 / 11524] loss: 0.062\n",
      "14:42:34.097233\n",
      "Train [4, 9601 / 11524] loss: 0.062\n",
      "14:43:23.350100\n",
      "Train [4, 9801 / 11524] loss: 0.062\n",
      "14:44:12.573894\n",
      "Train [4, 10001 / 11524] loss: 0.062\n",
      "14:45:01.856282\n",
      "Train [4, 10201 / 11524] loss: 0.062\n",
      "14:45:51.105008\n",
      "Train [4, 10401 / 11524] loss: 0.062\n",
      "14:46:40.337017\n",
      "Train [4, 10601 / 11524] loss: 0.062\n",
      "14:47:29.600928\n",
      "Train [4, 10801 / 11524] loss: 0.062\n",
      "14:48:18.829929\n",
      "Train [4, 11001 / 11524] loss: 0.062\n",
      "14:49:08.086824\n",
      "Train [4, 11201 / 11524] loss: 0.062\n",
      "14:49:57.213580\n",
      "Train [4, 11401 / 11524] loss: 0.062\n",
      "14:50:46.305191\n",
      "Validate [4,     1 /   641 ] loss: 0.065\n",
      "14:51:19.153293\n",
      "Test set: Accuracy: 46.01%\n",
      "Train [5, 1 / 11524] loss: 0.000\n",
      "15:06:20.091980\n",
      "Train [5, 201 / 11524] loss: 0.062\n",
      "15:07:09.075404\n",
      "Train [5, 401 / 11524] loss: 0.062\n",
      "15:07:58.053391\n",
      "Train [5, 601 / 11524] loss: 0.062\n",
      "15:08:47.325137\n",
      "Train [5, 801 / 11524] loss: 0.062\n",
      "15:09:36.742605\n",
      "Train [5, 1001 / 11524] loss: 0.062\n",
      "15:10:26.244769\n",
      "Train [5, 1201 / 11524] loss: 0.062\n",
      "15:11:15.623237\n",
      "Train [5, 1401 / 11524] loss: 0.062\n",
      "15:12:05.051579\n",
      "Train [5, 1601 / 11524] loss: 0.062\n",
      "15:12:54.278338\n",
      "Train [5, 1801 / 11524] loss: 0.062\n",
      "15:13:43.403648\n",
      "Train [5, 2001 / 11524] loss: 0.062\n",
      "15:14:32.667226\n",
      "Train [5, 2201 / 11524] loss: 0.062\n",
      "15:15:21.950622\n",
      "Train [5, 2401 / 11524] loss: 0.062\n",
      "15:16:11.305666\n",
      "Train [5, 2601 / 11524] loss: 0.062\n",
      "15:17:00.638577\n",
      "Train [5, 2801 / 11524] loss: 0.062\n",
      "15:17:49.825910\n",
      "Train [5, 3001 / 11524] loss: 0.062\n",
      "15:18:39.136251\n",
      "Train [5, 3201 / 11524] loss: 0.062\n",
      "15:19:28.386080\n",
      "Train [5, 3401 / 11524] loss: 0.062\n",
      "15:20:17.567416\n",
      "Train [5, 3601 / 11524] loss: 0.062\n",
      "15:21:06.807124\n",
      "Train [5, 3801 / 11524] loss: 0.062\n",
      "15:21:55.966072\n",
      "Train [5, 4001 / 11524] loss: 0.062\n",
      "15:22:45.121537\n",
      "Train [5, 4201 / 11524] loss: 0.062\n",
      "15:23:34.294323\n",
      "Train [5, 4401 / 11524] loss: 0.062\n",
      "15:24:23.459413\n",
      "Train [5, 4601 / 11524] loss: 0.061\n",
      "15:25:12.726002\n",
      "Train [5, 4801 / 11524] loss: 0.062\n",
      "15:26:01.790073\n",
      "Train [5, 5001 / 11524] loss: 0.062\n",
      "15:26:50.914984\n",
      "Train [5, 5201 / 11524] loss: 0.061\n",
      "15:27:40.048118\n",
      "Train [5, 5401 / 11524] loss: 0.062\n",
      "15:28:29.313407\n",
      "Train [5, 5601 / 11524] loss: 0.062\n",
      "15:29:18.520638\n",
      "Train [5, 5801 / 11524] loss: 0.062\n",
      "15:30:07.778833\n",
      "Train [5, 6001 / 11524] loss: 0.062\n",
      "15:30:56.950065\n",
      "Train [5, 6201 / 11524] loss: 0.062\n",
      "15:31:46.185113\n",
      "Train [5, 6401 / 11524] loss: 0.062\n",
      "15:32:35.491132\n",
      "Train [5, 6601 / 11524] loss: 0.062\n",
      "15:33:24.822517\n",
      "Train [5, 6801 / 11524] loss: 0.062\n",
      "15:34:13.961286\n",
      "Train [5, 7001 / 11524] loss: 0.062\n",
      "15:35:03.238219\n",
      "Train [5, 7201 / 11524] loss: 0.062\n",
      "15:35:52.455179\n",
      "Train [5, 7401 / 11524] loss: 0.062\n",
      "15:36:41.572068\n",
      "Train [5, 7601 / 11524] loss: 0.062\n",
      "15:37:30.698039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train [5, 7801 / 11524] loss: 0.062\n",
      "15:38:19.808043\n",
      "Train [5, 8001 / 11524] loss: 0.062\n",
      "15:39:08.875158\n",
      "Train [5, 8201 / 11524] loss: 0.062\n",
      "15:39:58.150527\n",
      "Train [5, 8401 / 11524] loss: 0.062\n",
      "15:40:47.376791\n",
      "Train [5, 8601 / 11524] loss: 0.062\n",
      "15:41:36.542419\n",
      "Train [5, 8801 / 11524] loss: 0.062\n",
      "15:42:25.843971\n",
      "Train [5, 9001 / 11524] loss: 0.062\n",
      "15:43:15.018541\n",
      "Train [5, 9201 / 11524] loss: 0.062\n",
      "15:44:04.305027\n",
      "Train [5, 9401 / 11524] loss: 0.062\n",
      "15:44:53.491098\n",
      "Train [5, 9601 / 11524] loss: 0.062\n",
      "15:45:42.750031\n",
      "Train [5, 9801 / 11524] loss: 0.062\n",
      "15:46:32.003965\n",
      "Train [5, 10001 / 11524] loss: 0.062\n",
      "15:47:21.121550\n",
      "Train [5, 10201 / 11524] loss: 0.062\n",
      "15:48:10.326088\n",
      "Train [5, 10401 / 11524] loss: 0.062\n",
      "15:48:59.559623\n",
      "Train [5, 10601 / 11524] loss: 0.062\n",
      "15:49:48.708880\n",
      "Train [5, 10801 / 11524] loss: 0.062\n",
      "15:50:37.861171\n",
      "Train [5, 11001 / 11524] loss: 0.062\n",
      "15:51:27.094223\n",
      "Train [5, 11201 / 11524] loss: 0.062\n",
      "15:52:16.228771\n",
      "Train [5, 11401 / 11524] loss: 0.062\n",
      "15:53:05.317622\n",
      "Validate [5,     1 /   641 ] loss: 0.063\n",
      "15:53:38.524020\n",
      "Test set: Accuracy: 39.85%\n",
      "Train [6, 1 / 11524] loss: 0.000\n",
      "16:08:51.474016\n",
      "Train [6, 201 / 11524] loss: 0.062\n",
      "16:09:40.453782\n",
      "Train [6, 401 / 11524] loss: 0.062\n",
      "16:10:29.376764\n",
      "Train [6, 601 / 11524] loss: 0.061\n",
      "16:11:18.632464\n",
      "Train [6, 801 / 11524] loss: 0.061\n",
      "16:12:08.036341\n",
      "Train [6, 1001 / 11524] loss: 0.062\n",
      "16:12:57.508179\n",
      "Train [6, 1201 / 11524] loss: 0.062\n",
      "16:13:47.085031\n",
      "Train [6, 1401 / 11524] loss: 0.062\n",
      "16:14:36.410917\n",
      "Train [6, 1601 / 11524] loss: 0.061\n",
      "16:15:25.601459\n",
      "Train [6, 1801 / 11524] loss: 0.062\n",
      "16:16:14.773715\n",
      "Train [6, 2001 / 11524] loss: 0.062\n",
      "16:17:03.874470\n",
      "Train [6, 2201 / 11524] loss: 0.062\n",
      "16:17:52.991290\n",
      "Train [6, 2401 / 11524] loss: 0.061\n",
      "16:18:42.100888\n",
      "Train [6, 2601 / 11524] loss: 0.062\n",
      "16:19:31.423257\n",
      "Train [6, 2801 / 11524] loss: 0.062\n",
      "16:20:20.742928\n",
      "Train [6, 3001 / 11524] loss: 0.062\n",
      "16:21:09.973899\n",
      "Train [6, 3201 / 11524] loss: 0.061\n",
      "16:21:59.179046\n",
      "Train [6, 3401 / 11524] loss: 0.062\n",
      "16:22:48.413735\n",
      "Train [6, 3601 / 11524] loss: 0.062\n",
      "16:23:37.614672\n",
      "Train [6, 3801 / 11524] loss: 0.061\n",
      "16:24:26.821496\n",
      "Train [6, 4001 / 11524] loss: 0.062\n",
      "16:25:15.925315\n",
      "Train [6, 4201 / 11524] loss: 0.062\n",
      "16:26:05.064795\n",
      "Train [6, 4401 / 11524] loss: 0.062\n",
      "16:26:54.280855\n",
      "Train [6, 4601 / 11524] loss: 0.062\n",
      "16:27:43.396771\n",
      "Train [6, 4801 / 11524] loss: 0.062\n",
      "16:28:32.717314\n",
      "Train [6, 5001 / 11524] loss: 0.062\n",
      "16:29:21.886260\n",
      "Train [6, 5201 / 11524] loss: 0.062\n",
      "16:30:11.032887\n",
      "Train [6, 5401 / 11524] loss: 0.062\n",
      "16:31:00.261800\n",
      "Train [6, 5601 / 11524] loss: 0.062\n",
      "16:31:49.345535\n",
      "Train [6, 5801 / 11524] loss: 0.062\n",
      "16:32:38.386896\n",
      "Train [6, 6001 / 11524] loss: 0.062\n",
      "16:33:27.607647\n",
      "Train [6, 6201 / 11524] loss: 0.062\n",
      "16:34:16.928843\n",
      "Train [6, 6401 / 11524] loss: 0.061\n",
      "16:35:06.086451\n",
      "Train [6, 6601 / 11524] loss: 0.062\n",
      "16:35:55.336901\n",
      "Train [6, 6801 / 11524] loss: 0.062\n",
      "16:36:44.595363\n",
      "Train [6, 7001 / 11524] loss: 0.061\n",
      "16:37:33.882825\n",
      "Train [6, 7201 / 11524] loss: 0.062\n",
      "16:38:23.181816\n",
      "Train [6, 7401 / 11524] loss: 0.061\n",
      "16:39:12.367812\n",
      "Train [6, 7601 / 11524] loss: 0.062\n",
      "16:40:01.477795\n",
      "Train [6, 7801 / 11524] loss: 0.061\n",
      "16:40:50.630830\n",
      "Train [6, 8001 / 11524] loss: 0.061\n",
      "16:41:39.906725\n",
      "Train [6, 8201 / 11524] loss: 0.061\n",
      "16:42:29.129826\n",
      "Train [6, 8401 / 11524] loss: 0.061\n",
      "16:43:18.337335\n",
      "Train [6, 8601 / 11524] loss: 0.061\n",
      "16:44:07.594682\n",
      "Train [6, 8801 / 11524] loss: 0.061\n",
      "16:44:56.836411\n",
      "Train [6, 9001 / 11524] loss: 0.061\n",
      "16:45:46.053690\n",
      "Train [6, 9201 / 11524] loss: 0.061\n",
      "16:46:35.222100\n",
      "Train [6, 9401 / 11524] loss: 0.061\n",
      "16:47:24.373455\n",
      "Train [6, 9601 / 11524] loss: 0.061\n",
      "16:48:13.609600\n",
      "Train [6, 9801 / 11524] loss: 0.062\n",
      "16:49:02.737431\n",
      "Train [6, 10001 / 11524] loss: 0.062\n",
      "16:49:52.026251\n",
      "Train [6, 10201 / 11524] loss: 0.061\n",
      "16:50:41.185286\n",
      "Train [6, 10401 / 11524] loss: 0.061\n",
      "16:51:30.201850\n",
      "Train [6, 10601 / 11524] loss: 0.061\n",
      "16:52:19.390616\n",
      "Train [6, 10801 / 11524] loss: 0.061\n",
      "16:53:08.527455\n",
      "Train [6, 11001 / 11524] loss: 0.061\n",
      "16:53:57.595030\n",
      "Train [6, 11201 / 11524] loss: 0.062\n",
      "16:54:46.772210\n",
      "Train [6, 11401 / 11524] loss: 0.061\n",
      "16:55:35.920321\n",
      "Validate [6,     1 /   641 ] loss: 0.102\n",
      "16:56:08.697848\n",
      "Test set: Accuracy: 44.98%\n",
      "Train [7, 1 / 11524] loss: 0.000\n",
      "17:11:10.435014\n",
      "Train [7, 201 / 11524] loss: 0.061\n",
      "17:11:59.343099\n",
      "Train [7, 401 / 11524] loss: 0.062\n",
      "17:12:48.319993\n",
      "Train [7, 601 / 11524] loss: 0.061\n",
      "17:13:37.678506\n",
      "Train [7, 801 / 11524] loss: 0.061\n",
      "17:14:27.232764\n",
      "Train [7, 1001 / 11524] loss: 0.061\n",
      "17:15:16.638868\n",
      "Train [7, 1201 / 11524] loss: 0.062\n",
      "17:16:06.221513\n",
      "Train [7, 1401 / 11524] loss: 0.061\n",
      "17:16:55.554415\n",
      "Train [7, 1601 / 11524] loss: 0.061\n",
      "17:17:44.786951\n",
      "Train [7, 1801 / 11524] loss: 0.061\n",
      "17:18:34.137592\n",
      "Train [7, 2001 / 11524] loss: 0.061\n",
      "17:19:23.548897\n",
      "Train [7, 2201 / 11524] loss: 0.061\n",
      "17:20:12.831837\n",
      "Train [7, 2401 / 11524] loss: 0.062\n",
      "17:21:02.132133\n",
      "Train [7, 2601 / 11524] loss: 0.061\n",
      "17:21:51.332169\n",
      "Train [7, 2801 / 11524] loss: 0.062\n",
      "17:22:40.522163\n",
      "Train [7, 3001 / 11524] loss: 0.061\n",
      "17:23:29.647053\n",
      "Train [7, 3201 / 11524] loss: 0.061\n",
      "17:24:18.929398\n",
      "Train [7, 3401 / 11524] loss: 0.061\n",
      "17:25:08.269478\n",
      "Train [7, 3601 / 11524] loss: 0.061\n",
      "17:25:57.587112\n",
      "Train [7, 3801 / 11524] loss: 0.061\n",
      "17:26:46.791366\n",
      "Train [7, 4001 / 11524] loss: 0.061\n",
      "17:27:36.066445\n",
      "Train [7, 4201 / 11524] loss: 0.061\n",
      "17:28:25.251854\n",
      "Train [7, 4401 / 11524] loss: 0.061\n",
      "17:29:14.444688\n",
      "Train [7, 4601 / 11524] loss: 0.061\n",
      "17:30:03.628553\n",
      "Train [7, 4801 / 11524] loss: 0.061\n",
      "17:30:52.841005\n",
      "Train [7, 5001 / 11524] loss: 0.061\n",
      "17:31:42.112673\n",
      "Train [7, 5201 / 11524] loss: 0.061\n",
      "17:32:31.326094\n",
      "Train [7, 5401 / 11524] loss: 0.061\n",
      "17:33:20.377181\n",
      "Train [7, 5601 / 11524] loss: 0.061\n",
      "17:34:09.633010\n",
      "Train [7, 5801 / 11524] loss: 0.061\n",
      "17:34:58.859111\n",
      "Train [7, 6001 / 11524] loss: 0.062\n",
      "17:35:48.194373\n",
      "Train [7, 6201 / 11524] loss: 0.062\n",
      "17:36:37.309468\n",
      "Train [7, 6401 / 11524] loss: 0.061\n",
      "17:37:26.608084\n",
      "Train [7, 6601 / 11524] loss: 0.061\n",
      "17:38:15.884192\n",
      "Train [7, 6801 / 11524] loss: 0.061\n",
      "17:39:05.069393\n",
      "Train [7, 7001 / 11524] loss: 0.062\n",
      "17:39:54.329600\n",
      "Train [7, 7201 / 11524] loss: 0.061\n",
      "17:40:43.659551\n",
      "Train [7, 7401 / 11524] loss: 0.061\n",
      "17:41:32.942083\n",
      "Train [7, 7601 / 11524] loss: 0.061\n",
      "17:42:22.219284\n",
      "Train [7, 7801 / 11524] loss: 0.061\n",
      "17:43:11.627371\n",
      "Train [7, 8001 / 11524] loss: 0.061\n",
      "17:44:00.889598\n",
      "Train [7, 8201 / 11524] loss: 0.061\n",
      "17:44:50.115550\n",
      "Train [7, 8401 / 11524] loss: 0.061\n",
      "17:45:39.381722\n",
      "Train [7, 8601 / 11524] loss: 0.061\n",
      "17:46:28.617965\n",
      "Train [7, 8801 / 11524] loss: 0.062\n",
      "17:47:17.932893\n",
      "Train [7, 9001 / 11524] loss: 0.061\n",
      "17:48:07.051318\n",
      "Train [7, 9201 / 11524] loss: 0.061\n",
      "17:48:56.216554\n",
      "Train [7, 9401 / 11524] loss: 0.061\n",
      "17:49:45.627398\n",
      "Train [7, 9601 / 11524] loss: 0.061\n",
      "17:50:34.916357\n",
      "Train [7, 9801 / 11524] loss: 0.061\n",
      "17:51:24.255144\n",
      "Train [7, 10001 / 11524] loss: 0.061\n",
      "17:52:13.494237\n",
      "Train [7, 10201 / 11524] loss: 0.061\n",
      "17:53:02.775742\n",
      "Train [7, 10401 / 11524] loss: 0.061\n",
      "17:53:52.147633\n",
      "Train [7, 10601 / 11524] loss: 0.061\n",
      "17:54:41.423850\n",
      "Train [7, 10801 / 11524] loss: 0.061\n",
      "17:55:30.656581\n",
      "Train [7, 11001 / 11524] loss: 0.061\n",
      "17:56:19.947192\n",
      "Train [7, 11201 / 11524] loss: 0.061\n",
      "17:57:09.118257\n",
      "Train [7, 11401 / 11524] loss: 0.061\n",
      "17:57:58.373045\n",
      "Validate [7,     1 /   641 ] loss: 0.075\n",
      "17:58:31.323957\n",
      "Test set: Accuracy: 47.06%\n",
      "Train [8, 1 / 11524] loss: 0.000\n",
      "18:13:42.887068\n",
      "Train [8, 201 / 11524] loss: 0.061\n",
      "18:14:31.825994\n",
      "Train [8, 401 / 11524] loss: 0.061\n",
      "18:15:20.702193\n",
      "Train [8, 601 / 11524] loss: 0.061\n",
      "18:16:09.814233\n",
      "Train [8, 801 / 11524] loss: 0.061\n",
      "18:16:59.200351\n",
      "Train [8, 1001 / 11524] loss: 0.062\n",
      "18:17:48.868834\n",
      "Train [8, 1201 / 11524] loss: 0.061\n",
      "18:18:38.532230\n",
      "Train [8, 1401 / 11524] loss: 0.061\n",
      "18:19:28.055726\n",
      "Train [8, 1601 / 11524] loss: 0.061\n",
      "18:20:17.567283\n",
      "Train [8, 1801 / 11524] loss: 0.061\n",
      "18:21:06.875128\n",
      "Train [8, 2001 / 11524] loss: 0.061\n",
      "18:21:56.233923\n",
      "Train [8, 2201 / 11524] loss: 0.061\n",
      "18:22:45.552802\n",
      "Train [8, 2401 / 11524] loss: 0.061\n",
      "18:23:34.707602\n",
      "Train [8, 2601 / 11524] loss: 0.061\n",
      "18:24:24.065244\n",
      "Train [8, 2801 / 11524] loss: 0.061\n",
      "18:25:13.263734\n",
      "Train [8, 3001 / 11524] loss: 0.061\n",
      "18:26:02.435793\n",
      "Train [8, 3201 / 11524] loss: 0.061\n",
      "18:26:51.685529\n",
      "Train [8, 3401 / 11524] loss: 0.061\n",
      "18:27:40.830883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train [8, 3601 / 11524] loss: 0.061\n",
      "18:28:30.093644\n",
      "Train [8, 3801 / 11524] loss: 0.061\n",
      "18:29:19.331115\n",
      "Train [8, 4001 / 11524] loss: 0.061\n",
      "18:30:08.543496\n",
      "Train [8, 4201 / 11524] loss: 0.062\n",
      "18:30:57.803518\n",
      "Train [8, 4401 / 11524] loss: 0.061\n",
      "18:31:47.104003\n",
      "Train [8, 4601 / 11524] loss: 0.061\n",
      "18:32:36.352783\n",
      "Train [8, 4801 / 11524] loss: 0.061\n",
      "18:33:25.561756\n",
      "Train [8, 5001 / 11524] loss: 0.061\n",
      "18:34:14.754497\n",
      "Train [8, 5201 / 11524] loss: 0.061\n",
      "18:35:04.025481\n",
      "Train [8, 5401 / 11524] loss: 0.061\n",
      "18:35:53.089979\n",
      "Train [8, 5601 / 11524] loss: 0.061\n",
      "18:36:42.364914\n",
      "Train [8, 5801 / 11524] loss: 0.061\n",
      "18:37:31.528359\n",
      "Train [8, 6001 / 11524] loss: 0.061\n",
      "18:38:20.701033\n",
      "Train [8, 6201 / 11524] loss: 0.061\n",
      "18:39:09.860998\n",
      "Train [8, 6401 / 11524] loss: 0.061\n",
      "18:39:59.066759\n",
      "Train [8, 6601 / 11524] loss: 0.061\n",
      "18:40:48.159239\n",
      "Train [8, 6801 / 11524] loss: 0.061\n",
      "18:41:37.342810\n",
      "Train [8, 7001 / 11524] loss: 0.061\n",
      "18:42:26.724716\n",
      "Train [8, 7201 / 11524] loss: 0.061\n",
      "18:43:15.921644\n",
      "Train [8, 7401 / 11524] loss: 0.061\n",
      "18:44:05.122550\n",
      "Train [8, 7601 / 11524] loss: 0.061\n",
      "18:44:54.310574\n",
      "Train [8, 7801 / 11524] loss: 0.061\n",
      "18:45:43.545236\n",
      "Train [8, 8001 / 11524] loss: 0.061\n",
      "18:46:32.903936\n",
      "Train [8, 8201 / 11524] loss: 0.061\n",
      "18:47:22.002297\n",
      "Train [8, 8401 / 11524] loss: 0.061\n",
      "18:48:11.133163\n",
      "Train [8, 8601 / 11524] loss: 0.061\n",
      "18:49:00.381164\n",
      "Train [8, 8801 / 11524] loss: 0.061\n",
      "18:49:49.667316\n",
      "Train [8, 9001 / 11524] loss: 0.061\n",
      "18:50:38.883099\n",
      "Train [8, 9201 / 11524] loss: 0.061\n",
      "18:51:28.117844\n",
      "Train [8, 9401 / 11524] loss: 0.061\n",
      "18:52:17.340050\n",
      "Train [8, 9601 / 11524] loss: 0.061\n",
      "18:53:06.413787\n",
      "Train [8, 9801 / 11524] loss: 0.061\n",
      "18:53:55.610669\n",
      "Train [8, 10001 / 11524] loss: 0.061\n",
      "18:54:44.717061\n",
      "Train [8, 10201 / 11524] loss: 0.061\n",
      "18:55:33.956821\n",
      "Train [8, 10401 / 11524] loss: 0.061\n",
      "18:56:23.099997\n",
      "Train [8, 10601 / 11524] loss: 0.061\n",
      "18:57:12.358867\n",
      "Train [8, 10801 / 11524] loss: 0.061\n",
      "18:58:01.577156\n",
      "Train [8, 11001 / 11524] loss: 0.061\n",
      "18:58:50.706332\n",
      "Train [8, 11201 / 11524] loss: 0.061\n",
      "18:59:40.245911\n",
      "Train [8, 11401 / 11524] loss: 0.061\n",
      "19:00:29.360094\n",
      "Validate [8,     1 /   641 ] loss: 0.062\n",
      "19:01:02.320877\n",
      "Test set: Accuracy: 59.37%\n",
      "Train [9, 1 / 11524] loss: 0.000\n",
      "19:16:13.605491\n",
      "Train [9, 201 / 11524] loss: 0.061\n",
      "19:17:02.604328\n",
      "Train [9, 401 / 11524] loss: 0.061\n",
      "19:17:51.681869\n",
      "Train [9, 601 / 11524] loss: 0.061\n",
      "19:18:41.280213\n",
      "Train [9, 801 / 11524] loss: 0.061\n",
      "19:19:31.174263\n",
      "Train [9, 1001 / 11524] loss: 0.061\n",
      "19:20:20.845850\n",
      "Train [9, 1201 / 11524] loss: 0.061\n",
      "19:21:10.450288\n",
      "Train [9, 1401 / 11524] loss: 0.061\n",
      "19:22:00.148453\n",
      "Train [9, 1601 / 11524] loss: 0.061\n",
      "19:22:49.583109\n",
      "Train [9, 1801 / 11524] loss: 0.061\n",
      "19:23:39.181509\n",
      "Train [9, 2001 / 11524] loss: 0.061\n",
      "19:24:28.866187\n",
      "Train [9, 2201 / 11524] loss: 0.061\n",
      "19:25:18.441170\n",
      "Train [9, 2401 / 11524] loss: 0.061\n",
      "19:26:07.856490\n",
      "Train [9, 2601 / 11524] loss: 0.061\n",
      "19:26:57.524210\n",
      "Train [9, 2801 / 11524] loss: 0.062\n",
      "19:27:47.044365\n",
      "Train [9, 3001 / 11524] loss: 0.061\n",
      "19:28:36.462994\n",
      "Train [9, 3201 / 11524] loss: 0.061\n",
      "19:29:25.965810\n",
      "Train [9, 3401 / 11524] loss: 0.061\n",
      "19:30:15.400103\n",
      "Train [9, 3601 / 11524] loss: 0.061\n",
      "19:31:04.861680\n",
      "Train [9, 3801 / 11524] loss: 0.061\n",
      "19:31:54.321522\n",
      "Train [9, 4001 / 11524] loss: 0.061\n",
      "19:32:43.732332\n",
      "Train [9, 4201 / 11524] loss: 0.061\n",
      "19:33:33.304433\n",
      "Train [9, 4401 / 11524] loss: 0.061\n",
      "19:34:22.698766\n",
      "Train [9, 4601 / 11524] loss: 0.061\n",
      "19:35:12.169542\n",
      "Train [9, 4801 / 11524] loss: 0.061\n",
      "19:36:01.713493\n",
      "Train [9, 5001 / 11524] loss: 0.061\n",
      "19:36:51.386687\n",
      "Train [9, 5201 / 11524] loss: 0.061\n",
      "19:37:40.948387\n",
      "Train [9, 5401 / 11524] loss: 0.061\n",
      "19:38:30.591375\n",
      "Train [9, 5601 / 11524] loss: 0.061\n",
      "19:39:20.198819\n",
      "Train [9, 5801 / 11524] loss: 0.061\n",
      "19:40:09.830426\n",
      "Train [9, 6001 / 11524] loss: 0.061\n",
      "19:40:59.515575\n",
      "Train [9, 6201 / 11524] loss: 0.061\n",
      "19:41:49.296883\n",
      "Train [9, 6401 / 11524] loss: 0.061\n",
      "19:42:38.776125\n",
      "Train [9, 6601 / 11524] loss: 0.061\n",
      "19:43:28.405839\n",
      "Train [9, 6801 / 11524] loss: 0.061\n",
      "19:44:17.979349\n",
      "Train [9, 7001 / 11524] loss: 0.061\n",
      "19:45:07.731935\n",
      "Train [9, 7201 / 11524] loss: 0.061\n",
      "19:45:57.278421\n",
      "Train [9, 7401 / 11524] loss: 0.061\n",
      "19:46:46.876935\n",
      "Train [9, 7601 / 11524] loss: 0.061\n",
      "19:47:36.350814\n",
      "Train [9, 7801 / 11524] loss: 0.061\n",
      "19:48:26.009971\n",
      "Train [9, 8001 / 11524] loss: 0.061\n",
      "19:49:15.682228\n",
      "Train [9, 8201 / 11524] loss: 0.061\n",
      "19:50:05.224620\n",
      "Train [9, 8401 / 11524] loss: 0.061\n",
      "19:50:54.886415\n",
      "Train [9, 8601 / 11524] loss: 0.061\n",
      "19:51:44.515831\n",
      "Train [9, 8801 / 11524] loss: 0.061\n",
      "19:52:34.128330\n",
      "Train [9, 9001 / 11524] loss: 0.061\n",
      "19:53:23.818321\n",
      "Train [9, 9201 / 11524] loss: 0.061\n",
      "19:54:13.519784\n",
      "Train [9, 9401 / 11524] loss: 0.061\n",
      "19:55:03.207174\n",
      "Train [9, 9601 / 11524] loss: 0.061\n",
      "19:55:52.909611\n",
      "Train [9, 9801 / 11524] loss: 0.061\n",
      "19:56:42.680786\n",
      "Train [9, 10001 / 11524] loss: 0.061\n",
      "19:57:32.322649\n",
      "Train [9, 10201 / 11524] loss: 0.061\n",
      "19:58:21.903338\n",
      "Train [9, 10401 / 11524] loss: 0.061\n",
      "19:59:11.648871\n",
      "Train [9, 10601 / 11524] loss: 0.061\n",
      "20:00:01.409292\n",
      "Train [9, 10801 / 11524] loss: 0.061\n",
      "20:00:51.045855\n",
      "Train [9, 11001 / 11524] loss: 0.061\n",
      "20:01:40.619984\n",
      "Train [9, 11201 / 11524] loss: 0.061\n",
      "20:02:30.316910\n",
      "Train [9, 11401 / 11524] loss: 0.061\n",
      "20:03:19.929321\n",
      "Validate [9,     1 /   641 ] loss: 0.060\n",
      "20:03:53.134301\n",
      "Test set: Accuracy: 47.91%\n",
      "Train [10, 1 / 11524] loss: 0.000\n",
      "20:18:55.577226\n",
      "Train [10, 201 / 11524] loss: 0.061\n",
      "20:19:44.510904\n",
      "Train [10, 401 / 11524] loss: 0.061\n",
      "20:20:33.673527\n",
      "Train [10, 601 / 11524] loss: 0.061\n",
      "20:21:23.395416\n",
      "Train [10, 801 / 11524] loss: 0.061\n",
      "20:22:13.210930\n",
      "Train [10, 1001 / 11524] loss: 0.061\n",
      "20:23:03.098229\n",
      "Train [10, 1201 / 11524] loss: 0.061\n",
      "20:23:52.957492\n",
      "Train [10, 1401 / 11524] loss: 0.061\n",
      "20:24:42.731653\n",
      "Train [10, 1601 / 11524] loss: 0.061\n",
      "20:25:32.570418\n",
      "Train [10, 1801 / 11524] loss: 0.061\n",
      "20:26:22.303343\n",
      "Train [10, 2001 / 11524] loss: 0.061\n",
      "20:27:12.062491\n",
      "Train [10, 2201 / 11524] loss: 0.061\n",
      "20:28:01.789159\n",
      "Train [10, 2401 / 11524] loss: 0.061\n",
      "20:28:51.375867\n",
      "Train [10, 2601 / 11524] loss: 0.061\n",
      "20:29:41.284191\n",
      "Train [10, 2801 / 11524] loss: 0.061\n",
      "20:30:31.094659\n",
      "Train [10, 3001 / 11524] loss: 0.061\n",
      "20:31:20.814471\n",
      "Train [10, 3201 / 11524] loss: 0.061\n",
      "20:32:10.636141\n",
      "Train [10, 3401 / 11524] loss: 0.061\n",
      "20:33:00.383693\n",
      "Train [10, 3601 / 11524] loss: 0.061\n",
      "20:33:50.127227\n",
      "Train [10, 3801 / 11524] loss: 0.061\n",
      "20:34:39.750373\n",
      "Train [10, 4001 / 11524] loss: 0.061\n",
      "20:35:29.440786\n",
      "Train [10, 4201 / 11524] loss: 0.061\n",
      "20:36:19.070349\n",
      "Train [10, 4401 / 11524] loss: 0.061\n",
      "20:37:08.684418\n",
      "Train [10, 4601 / 11524] loss: 0.061\n",
      "20:37:58.407645\n",
      "Train [10, 4801 / 11524] loss: 0.061\n",
      "20:38:48.243146\n",
      "Train [10, 5001 / 11524] loss: 0.061\n",
      "20:39:38.003665\n",
      "Train [10, 5201 / 11524] loss: 0.061\n",
      "20:40:27.657827\n",
      "Train [10, 5401 / 11524] loss: 0.061\n",
      "20:41:17.430718\n",
      "Train [10, 5601 / 11524] loss: 0.061\n",
      "20:42:07.137452\n",
      "Train [10, 5801 / 11524] loss: 0.061\n",
      "20:42:56.864105\n",
      "Train [10, 6001 / 11524] loss: 0.061\n",
      "20:43:46.557162\n",
      "Train [10, 6201 / 11524] loss: 0.061\n",
      "20:44:36.273330\n",
      "Train [10, 6401 / 11524] loss: 0.061\n",
      "20:45:26.045021\n",
      "Train [10, 6601 / 11524] loss: 0.061\n",
      "20:46:15.866846\n",
      "Train [10, 6801 / 11524] loss: 0.061\n",
      "20:47:05.539265\n",
      "Train [10, 7001 / 11524] loss: 0.061\n",
      "20:47:55.189366\n",
      "Train [10, 7201 / 11524] loss: 0.061\n",
      "20:48:44.955172\n",
      "Train [10, 7401 / 11524] loss: 0.061\n",
      "20:49:34.724833\n",
      "Train [10, 7601 / 11524] loss: 0.061\n",
      "20:50:24.413558\n",
      "Train [10, 7801 / 11524] loss: 0.061\n",
      "20:51:14.217540\n",
      "Train [10, 8001 / 11524] loss: 0.061\n",
      "20:52:03.951432\n",
      "Train [10, 8201 / 11524] loss: 0.061\n",
      "20:52:53.640507\n",
      "Train [10, 8401 / 11524] loss: 0.061\n",
      "20:53:43.342121\n",
      "Train [10, 8601 / 11524] loss: 0.061\n",
      "20:54:33.139902\n",
      "Train [10, 8801 / 11524] loss: 0.061\n",
      "20:55:22.820129\n",
      "Train [10, 9001 / 11524] loss: 0.061\n",
      "20:56:12.538079\n",
      "Train [10, 9201 / 11524] loss: 0.061\n",
      "20:57:02.315097\n",
      "Train [10, 9401 / 11524] loss: 0.061\n",
      "20:57:52.130535\n",
      "Train [10, 9601 / 11524] loss: 0.061\n",
      "20:58:41.957173\n",
      "Train [10, 9801 / 11524] loss: 0.061\n",
      "20:59:31.753984\n",
      "Train [10, 10001 / 11524] loss: 0.061\n",
      "21:00:21.681263\n",
      "Train [10, 10201 / 11524] loss: 0.061\n",
      "21:01:11.592933\n",
      "Train [10, 10401 / 11524] loss: 0.061\n",
      "21:02:01.268039\n",
      "Train [10, 10601 / 11524] loss: 0.061\n",
      "21:02:51.148515\n",
      "Train [10, 10801 / 11524] loss: 0.061\n",
      "21:03:40.998510\n",
      "Train [10, 11001 / 11524] loss: 0.061\n",
      "21:04:30.738685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train [10, 11201 / 11524] loss: 0.061\n",
      "21:05:20.526703\n",
      "Train [10, 11401 / 11524] loss: 0.061\n",
      "21:06:10.402746\n",
      "Validate [10,     1 /   641 ] loss: 0.062\n",
      "21:06:43.357921\n",
      "Test set: Accuracy: 41.23%\n",
      "Train [11, 1 / 11524] loss: 0.000\n",
      "21:21:46.968078\n",
      "Train [11, 201 / 11524] loss: 0.061\n",
      "21:22:36.340353\n",
      "Train [11, 401 / 11524] loss: 0.061\n",
      "21:23:25.895086\n",
      "Train [11, 601 / 11524] loss: 0.061\n",
      "21:24:15.881822\n",
      "Train [11, 801 / 11524] loss: 0.061\n",
      "21:25:05.858864\n",
      "Train [11, 1001 / 11524] loss: 0.061\n",
      "21:25:55.886274\n",
      "Train [11, 1201 / 11524] loss: 0.061\n",
      "21:26:45.896416\n",
      "Train [11, 1401 / 11524] loss: 0.061\n",
      "21:27:35.841390\n",
      "Train [11, 1601 / 11524] loss: 0.061\n",
      "21:28:25.756965\n",
      "Train [11, 1801 / 11524] loss: 0.061\n",
      "21:29:15.615000\n",
      "Train [11, 2001 / 11524] loss: 0.061\n",
      "21:30:05.395578\n",
      "Train [11, 2201 / 11524] loss: 0.061\n",
      "21:30:55.245395\n",
      "Train [11, 2401 / 11524] loss: 0.061\n",
      "21:31:45.168304\n",
      "Train [11, 2601 / 11524] loss: 0.061\n",
      "21:32:35.005969\n",
      "Train [11, 2801 / 11524] loss: 0.061\n",
      "21:33:24.771679\n",
      "Train [11, 3001 / 11524] loss: 0.061\n",
      "21:34:14.462519\n",
      "Train [11, 3201 / 11524] loss: 0.061\n",
      "21:35:04.208227\n",
      "Train [11, 3401 / 11524] loss: 0.061\n",
      "21:35:53.911715\n",
      "Train [11, 3601 / 11524] loss: 0.061\n",
      "21:36:43.839895\n",
      "Train [11, 3801 / 11524] loss: 0.061\n",
      "21:37:33.721805\n",
      "Train [11, 4001 / 11524] loss: 0.061\n",
      "21:38:23.594616\n",
      "Train [11, 4201 / 11524] loss: 0.061\n",
      "21:39:13.280710\n",
      "Train [11, 4401 / 11524] loss: 0.061\n",
      "21:40:03.146522\n",
      "Train [11, 4601 / 11524] loss: 0.061\n",
      "21:40:52.921030\n",
      "Train [11, 4801 / 11524] loss: 0.061\n",
      "21:41:42.897274\n",
      "Train [11, 5001 / 11524] loss: 0.061\n",
      "21:42:32.742999\n",
      "Train [11, 5201 / 11524] loss: 0.061\n",
      "21:43:22.502145\n",
      "Train [11, 5401 / 11524] loss: 0.061\n",
      "21:44:12.277337\n",
      "Train [11, 5601 / 11524] loss: 0.061\n",
      "21:45:02.207518\n",
      "Train [11, 5801 / 11524] loss: 0.061\n",
      "21:45:52.230122\n",
      "Train [11, 6001 / 11524] loss: 0.061\n",
      "21:46:42.208746\n",
      "Train [11, 6201 / 11524] loss: 0.061\n",
      "21:47:32.190079\n",
      "Train [11, 6401 / 11524] loss: 0.061\n",
      "21:48:22.099216\n",
      "Train [11, 6601 / 11524] loss: 0.061\n",
      "21:49:12.053771\n",
      "Train [11, 6801 / 11524] loss: 0.061\n",
      "21:50:01.937355\n",
      "Train [11, 7001 / 11524] loss: 0.061\n",
      "21:50:51.929895\n",
      "Train [11, 7201 / 11524] loss: 0.061\n",
      "21:51:41.700914\n",
      "Train [11, 7401 / 11524] loss: 0.061\n",
      "21:52:31.597480\n",
      "Train [11, 7601 / 11524] loss: 0.061\n",
      "21:53:21.451095\n",
      "Train [11, 7801 / 11524] loss: 0.061\n",
      "21:54:11.312185\n",
      "Train [11, 8001 / 11524] loss: 0.061\n",
      "21:55:01.299363\n",
      "Train [11, 8201 / 11524] loss: 0.061\n",
      "21:55:51.366659\n",
      "Train [11, 8401 / 11524] loss: 0.061\n",
      "21:56:41.236112\n",
      "Train [11, 8601 / 11524] loss: 0.061\n",
      "21:57:31.155646\n",
      "Train [11, 8801 / 11524] loss: 0.061\n",
      "21:58:21.029623\n",
      "Train [11, 9001 / 11524] loss: 0.061\n",
      "21:59:10.924566\n",
      "Train [11, 9201 / 11524] loss: 0.061\n",
      "22:00:00.884389\n",
      "Train [11, 9401 / 11524] loss: 0.061\n",
      "22:00:50.823986\n",
      "Train [11, 9601 / 11524] loss: 0.061\n",
      "22:01:40.627765\n",
      "Train [11, 9801 / 11524] loss: 0.061\n",
      "22:02:30.638151\n",
      "Train [11, 10001 / 11524] loss: 0.061\n",
      "22:03:20.643322\n",
      "Train [11, 10201 / 11524] loss: 0.061\n",
      "22:04:10.634219\n",
      "Train [11, 10401 / 11524] loss: 0.061\n",
      "22:05:00.690949\n",
      "Train [11, 10601 / 11524] loss: 0.061\n",
      "22:05:50.504206\n",
      "Train [11, 10801 / 11524] loss: 0.061\n",
      "22:06:40.397950\n",
      "Train [11, 11001 / 11524] loss: 0.061\n",
      "22:07:30.234679\n",
      "Train [11, 11201 / 11524] loss: 0.061\n",
      "22:08:20.054941\n",
      "Train [11, 11401 / 11524] loss: 0.061\n",
      "22:09:10.133614\n",
      "Validate [11,     1 /   641 ] loss: 0.066\n",
      "22:09:43.779106\n",
      "Test set: Accuracy: 52.19%\n",
      "Train [12, 1 / 11524] loss: 0.000\n",
      "22:24:48.738522\n",
      "Train [12, 201 / 11524] loss: 0.061\n",
      "22:25:37.954911\n",
      "Train [12, 401 / 11524] loss: 0.061\n",
      "22:26:27.581780\n",
      "Train [12, 601 / 11524] loss: 0.061\n",
      "22:27:17.609077\n",
      "Train [12, 801 / 11524] loss: 0.061\n",
      "22:28:07.602475\n",
      "Train [12, 1001 / 11524] loss: 0.061\n",
      "22:28:57.711650\n",
      "Train [12, 1201 / 11524] loss: 0.061\n",
      "22:29:47.748986\n",
      "Train [12, 1401 / 11524] loss: 0.061\n",
      "22:30:37.769206\n",
      "Train [12, 1601 / 11524] loss: 0.061\n",
      "22:31:27.814200\n",
      "Train [12, 1801 / 11524] loss: 0.061\n",
      "22:32:17.790301\n",
      "Train [12, 2001 / 11524] loss: 0.061\n",
      "22:33:07.746823\n",
      "Train [12, 2201 / 11524] loss: 0.061\n",
      "22:33:57.617625\n",
      "Train [12, 2401 / 11524] loss: 0.061\n",
      "22:34:47.475528\n",
      "Train [12, 2601 / 11524] loss: 0.061\n",
      "22:35:37.324415\n",
      "Train [12, 2801 / 11524] loss: 0.061\n",
      "22:36:27.346323\n",
      "Train [12, 3001 / 11524] loss: 0.061\n",
      "22:37:17.246594\n",
      "Train [12, 3201 / 11524] loss: 0.061\n",
      "22:38:07.171620\n",
      "Train [12, 3401 / 11524] loss: 0.061\n",
      "22:38:57.098481\n",
      "Train [12, 3601 / 11524] loss: 0.061\n",
      "22:39:46.979594\n",
      "Train [12, 3801 / 11524] loss: 0.061\n",
      "22:40:36.970409\n",
      "Train [12, 4001 / 11524] loss: 0.061\n",
      "22:41:26.875665\n",
      "Train [12, 4201 / 11524] loss: 0.061\n",
      "22:42:16.833082\n",
      "Train [12, 4401 / 11524] loss: 0.061\n",
      "22:43:06.681425\n",
      "Train [12, 4601 / 11524] loss: 0.061\n",
      "22:43:56.647271\n",
      "Train [12, 4801 / 11524] loss: 0.061\n",
      "22:44:46.470354\n",
      "Train [12, 5001 / 11524] loss: 0.061\n",
      "22:45:36.536726\n",
      "Train [12, 5201 / 11524] loss: 0.061\n",
      "22:46:26.321582\n",
      "Train [12, 5401 / 11524] loss: 0.061\n",
      "22:47:16.322915\n",
      "Train [12, 5601 / 11524] loss: 0.061\n",
      "22:48:06.236482\n",
      "Train [12, 5801 / 11524] loss: 0.061\n",
      "22:48:56.305502\n",
      "Train [12, 6001 / 11524] loss: 0.061\n",
      "22:49:46.234376\n",
      "Train [12, 6201 / 11524] loss: 0.061\n",
      "22:50:36.205276\n",
      "Train [12, 6401 / 11524] loss: 0.061\n",
      "22:51:26.186312\n",
      "Train [12, 6601 / 11524] loss: 0.061\n",
      "22:52:16.199872\n",
      "Train [12, 6801 / 11524] loss: 0.061\n",
      "22:53:06.287495\n",
      "Train [12, 7001 / 11524] loss: 0.061\n",
      "22:53:56.161872\n",
      "Train [12, 7201 / 11524] loss: 0.061\n",
      "22:54:46.198144\n",
      "Train [12, 7401 / 11524] loss: 0.061\n",
      "22:55:36.149807\n",
      "Train [12, 7601 / 11524] loss: 0.061\n",
      "22:56:26.118259\n",
      "Train [12, 7801 / 11524] loss: 0.061\n",
      "22:57:15.996645\n",
      "Train [12, 8001 / 11524] loss: 0.061\n",
      "22:58:05.788152\n",
      "Train [12, 8201 / 11524] loss: 0.061\n",
      "22:58:55.756453\n",
      "Train [12, 8401 / 11524] loss: 0.061\n",
      "22:59:45.948808\n",
      "Train [12, 8601 / 11524] loss: 0.061\n",
      "23:00:35.885446\n",
      "Train [12, 8801 / 11524] loss: 0.061\n",
      "23:01:25.942034\n",
      "Train [12, 9001 / 11524] loss: 0.061\n",
      "23:02:16.007211\n",
      "Train [12, 9201 / 11524] loss: 0.061\n",
      "23:03:05.925795\n",
      "Train [12, 9401 / 11524] loss: 0.061\n",
      "23:03:55.973521\n",
      "Train [12, 9601 / 11524] loss: 0.061\n",
      "23:04:46.000743\n",
      "Train [12, 9801 / 11524] loss: 0.061\n",
      "23:05:36.000409\n",
      "Train [12, 10001 / 11524] loss: 0.061\n",
      "23:06:25.959278\n",
      "Train [12, 10201 / 11524] loss: 0.061\n",
      "23:07:15.989151\n",
      "Train [12, 10401 / 11524] loss: 0.061\n",
      "23:08:05.941139\n",
      "Train [12, 10601 / 11524] loss: 0.061\n",
      "23:08:55.855954\n",
      "Train [12, 10801 / 11524] loss: 0.061\n",
      "23:09:45.935111\n",
      "Train [12, 11001 / 11524] loss: 0.061\n",
      "23:10:36.039594\n",
      "Train [12, 11201 / 11524] loss: 0.061\n",
      "23:11:25.942938\n",
      "Train [12, 11401 / 11524] loss: 0.061\n",
      "23:12:15.959194\n",
      "Validate [12,     1 /   641 ] loss: 0.063\n",
      "23:12:49.691574\n",
      "Test set: Accuracy: 53.13%\n",
      "Train [13, 1 / 11524] loss: 0.000\n",
      "23:27:54.063714\n",
      "Train [13, 201 / 11524] loss: 0.061\n",
      "23:28:43.203211\n",
      "Train [13, 401 / 11524] loss: 0.061\n",
      "23:29:32.768255\n",
      "Train [13, 601 / 11524] loss: 0.061\n",
      "23:30:22.759575\n",
      "Train [13, 801 / 11524] loss: 0.061\n",
      "23:31:12.826564\n",
      "Train [13, 1001 / 11524] loss: 0.061\n",
      "23:32:03.002210\n",
      "Train [13, 1201 / 11524] loss: 0.061\n",
      "23:32:53.003833\n",
      "Train [13, 1401 / 11524] loss: 0.061\n",
      "23:33:43.150718\n",
      "Train [13, 1601 / 11524] loss: 0.061\n",
      "23:34:33.498123\n",
      "Train [13, 1801 / 11524] loss: 0.061\n",
      "23:35:23.723657\n",
      "Train [13, 2001 / 11524] loss: 0.061\n",
      "23:36:13.845534\n",
      "Train [13, 2201 / 11524] loss: 0.061\n",
      "23:37:03.882122\n",
      "Train [13, 2401 / 11524] loss: 0.061\n",
      "23:37:53.957101\n",
      "Train [13, 2601 / 11524] loss: 0.061\n",
      "23:38:43.981064\n",
      "Train [13, 2801 / 11524] loss: 0.061\n",
      "23:39:34.039878\n",
      "Train [13, 3001 / 11524] loss: 0.061\n",
      "23:40:24.083444\n",
      "Train [13, 3201 / 11524] loss: 0.061\n",
      "23:41:14.199195\n",
      "Train [13, 3401 / 11524] loss: 0.061\n",
      "23:42:04.310670\n",
      "Train [13, 3601 / 11524] loss: 0.061\n",
      "23:42:54.392800\n",
      "Train [13, 3801 / 11524] loss: 0.061\n",
      "23:43:44.407108\n",
      "Train [13, 4001 / 11524] loss: 0.061\n",
      "23:44:34.494403\n",
      "Train [13, 4201 / 11524] loss: 0.061\n",
      "23:45:24.581602\n",
      "Train [13, 4401 / 11524] loss: 0.061\n",
      "23:46:14.575043\n",
      "Train [13, 4601 / 11524] loss: 0.061\n",
      "23:47:04.676844\n",
      "Train [13, 4801 / 11524] loss: 0.061\n",
      "23:47:54.778662\n",
      "Train [13, 5001 / 11524] loss: 0.061\n",
      "23:48:44.747662\n",
      "Train [13, 5201 / 11524] loss: 0.061\n",
      "23:49:34.723221\n",
      "Train [13, 5401 / 11524] loss: 0.061\n",
      "23:50:24.780835\n",
      "Train [13, 5601 / 11524] loss: 0.061\n",
      "23:51:14.799417\n",
      "Train [13, 5801 / 11524] loss: 0.061\n",
      "23:52:04.940755\n",
      "Train [13, 6001 / 11524] loss: 0.061\n",
      "23:52:55.077240\n",
      "Train [13, 6201 / 11524] loss: 0.061\n",
      "23:53:45.252210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train [13, 6401 / 11524] loss: 0.061\n",
      "23:54:35.431593\n",
      "Train [13, 6601 / 11524] loss: 0.061\n",
      "23:55:25.567409\n",
      "Train [13, 6801 / 11524] loss: 0.061\n",
      "23:56:15.664679\n",
      "Train [13, 7001 / 11524] loss: 0.061\n",
      "23:57:05.730158\n",
      "Train [13, 7201 / 11524] loss: 0.061\n",
      "23:57:55.904097\n",
      "Train [13, 7401 / 11524] loss: 0.061\n",
      "23:58:46.056441\n",
      "Train [13, 7601 / 11524] loss: 0.061\n",
      "23:59:36.103200\n",
      "Train [13, 7801 / 11524] loss: 0.061\n",
      "00:00:26.174865\n",
      "Train [13, 8001 / 11524] loss: 0.061\n",
      "00:01:16.294206\n",
      "Train [13, 8201 / 11524] loss: 0.061\n",
      "00:02:06.414021\n",
      "Train [13, 8401 / 11524] loss: 0.061\n",
      "00:02:56.360331\n",
      "Train [13, 8601 / 11524] loss: 0.061\n",
      "00:03:46.455574\n",
      "Train [13, 8801 / 11524] loss: 0.061\n",
      "00:04:36.620655\n",
      "Train [13, 9001 / 11524] loss: 0.061\n",
      "00:05:26.737219\n",
      "Train [13, 9201 / 11524] loss: 0.061\n",
      "00:06:17.066601\n",
      "Train [13, 9401 / 11524] loss: 0.061\n",
      "00:07:07.195494\n",
      "Train [13, 9601 / 11524] loss: 0.061\n",
      "00:07:57.425625\n",
      "Train [13, 9801 / 11524] loss: 0.061\n",
      "00:08:47.507223\n",
      "Train [13, 10001 / 11524] loss: 0.061\n",
      "00:09:37.602333\n",
      "Train [13, 10201 / 11524] loss: 0.061\n",
      "00:10:27.900285\n",
      "Train [13, 10401 / 11524] loss: 0.061\n",
      "00:11:17.947383\n",
      "Train [13, 10601 / 11524] loss: 0.061\n",
      "00:12:08.322843\n",
      "Train [13, 10801 / 11524] loss: 0.061\n",
      "00:12:58.460878\n",
      "Train [13, 11001 / 11524] loss: 0.061\n",
      "00:13:48.505732\n",
      "Train [13, 11201 / 11524] loss: 0.061\n",
      "00:14:38.732928\n",
      "Train [13, 11401 / 11524] loss: 0.061\n",
      "00:15:28.857539\n",
      "Validate [13,     1 /   641 ] loss: 0.062\n",
      "00:16:02.455548\n",
      "Test set: Accuracy: 76.88%\n",
      "Train [14, 1 / 11524] loss: 0.000\n",
      "00:31:02.753502\n",
      "Train [14, 201 / 11524] loss: 0.061\n",
      "00:31:52.122773\n",
      "Train [14, 401 / 11524] loss: 0.061\n",
      "00:32:41.836009\n",
      "Train [14, 601 / 11524] loss: 0.061\n",
      "00:33:32.043856\n",
      "Train [14, 801 / 11524] loss: 0.061\n",
      "00:34:22.276007\n",
      "Train [14, 1001 / 11524] loss: 0.061\n",
      "00:35:12.573716\n",
      "Train [14, 1201 / 11524] loss: 0.061\n",
      "00:36:02.833289\n",
      "Train [14, 1401 / 11524] loss: 0.061\n",
      "00:36:52.946263\n",
      "Train [14, 1601 / 11524] loss: 0.061\n",
      "00:37:43.214420\n",
      "Train [14, 1801 / 11524] loss: 0.061\n",
      "00:38:33.311627\n",
      "Train [14, 2001 / 11524] loss: 0.061\n",
      "00:39:23.496926\n",
      "Train [14, 2201 / 11524] loss: 0.061\n",
      "00:40:13.839956\n",
      "Train [14, 2401 / 11524] loss: 0.061\n",
      "00:41:04.090326\n",
      "Train [14, 2601 / 11524] loss: 0.061\n",
      "00:41:54.008635\n",
      "Train [14, 2801 / 11524] loss: 0.061\n",
      "00:42:44.242815\n",
      "Train [14, 3001 / 11524] loss: 0.061\n",
      "00:43:34.269569\n",
      "Train [14, 3201 / 11524] loss: 0.061\n",
      "00:44:24.511792\n",
      "Train [14, 3401 / 11524] loss: 0.061\n",
      "00:45:14.845453\n",
      "Train [14, 3601 / 11524] loss: 0.061\n",
      "00:46:04.958350\n",
      "Train [14, 3801 / 11524] loss: 0.061\n",
      "00:46:55.102787\n",
      "Train [14, 4001 / 11524] loss: 0.061\n",
      "00:47:45.389855\n",
      "Train [14, 4201 / 11524] loss: 0.061\n",
      "00:48:35.568933\n",
      "Train [14, 4401 / 11524] loss: 0.061\n",
      "00:49:25.613936\n",
      "Train [14, 4601 / 11524] loss: 0.061\n",
      "00:50:15.919520\n",
      "Train [14, 4801 / 11524] loss: 0.061\n",
      "00:51:05.986366\n",
      "Train [14, 5001 / 11524] loss: 0.061\n",
      "00:51:56.128742\n",
      "Train [14, 5201 / 11524] loss: 0.061\n",
      "00:52:46.213894\n",
      "Train [14, 5401 / 11524] loss: 0.061\n",
      "00:53:36.418085\n",
      "Train [14, 5601 / 11524] loss: 0.061\n",
      "00:54:26.592295\n",
      "Train [14, 5801 / 11524] loss: 0.061\n",
      "00:55:16.778219\n",
      "Train [14, 6001 / 11524] loss: 0.061\n",
      "00:56:06.878698\n",
      "Train [14, 6201 / 11524] loss: 0.061\n",
      "00:56:57.148898\n",
      "Train [14, 6401 / 11524] loss: 0.061\n",
      "00:57:47.271913\n",
      "Train [14, 6601 / 11524] loss: 0.061\n",
      "00:58:37.427594\n",
      "Train [14, 6801 / 11524] loss: 0.061\n",
      "00:59:27.587025\n",
      "Train [14, 7001 / 11524] loss: 0.061\n",
      "01:00:17.611730\n",
      "Train [14, 7201 / 11524] loss: 0.061\n",
      "01:01:07.794904\n",
      "Train [14, 7401 / 11524] loss: 0.061\n",
      "01:01:57.916398\n",
      "Train [14, 7601 / 11524] loss: 0.061\n",
      "01:02:48.156452\n",
      "Train [14, 7801 / 11524] loss: 0.061\n",
      "01:03:38.387773\n",
      "Train [14, 8001 / 11524] loss: 0.061\n",
      "01:04:28.561107\n",
      "Train [14, 8201 / 11524] loss: 0.061\n",
      "01:05:19.133466\n",
      "Train [14, 8401 / 11524] loss: 0.061\n",
      "01:06:09.326958\n",
      "Train [14, 8601 / 11524] loss: 0.061\n",
      "01:06:59.621594\n",
      "Train [14, 8801 / 11524] loss: 0.061\n",
      "01:07:49.942024\n",
      "Train [14, 9001 / 11524] loss: 0.061\n",
      "01:08:40.144261\n",
      "Train [14, 9201 / 11524] loss: 0.061\n",
      "01:09:30.181358\n",
      "Train [14, 9401 / 11524] loss: 0.061\n",
      "01:10:20.350811\n",
      "Train [14, 9601 / 11524] loss: 0.061\n",
      "01:11:10.628459\n",
      "Train [14, 9801 / 11524] loss: 0.061\n",
      "01:12:00.912139\n",
      "Train [14, 10001 / 11524] loss: 0.061\n",
      "01:12:51.143052\n",
      "Train [14, 10201 / 11524] loss: 0.061\n",
      "01:13:41.265301\n",
      "Train [14, 10401 / 11524] loss: 0.061\n",
      "01:14:31.490410\n",
      "Train [14, 10601 / 11524] loss: 0.061\n",
      "01:15:21.890777\n",
      "Train [14, 10801 / 11524] loss: 0.061\n",
      "01:16:12.111320\n",
      "Train [14, 11001 / 11524] loss: 0.061\n",
      "01:17:02.182847\n",
      "Train [14, 11201 / 11524] loss: 0.061\n",
      "01:17:52.593473\n",
      "Train [14, 11401 / 11524] loss: 0.061\n",
      "01:18:42.909446\n",
      "Validate [14,     1 /   641 ] loss: 0.064\n",
      "01:19:16.700951\n",
      "Test set: Accuracy: 50.94%\n",
      "Train [15, 1 / 11524] loss: 0.000\n",
      "01:34:19.346196\n",
      "Train [15, 201 / 11524] loss: 0.061\n",
      "01:35:08.879614\n",
      "Train [15, 401 / 11524] loss: 0.061\n",
      "01:35:58.767292\n",
      "Train [15, 601 / 11524] loss: 0.061\n",
      "01:36:49.057690\n",
      "Train [15, 801 / 11524] loss: 0.061\n",
      "01:37:39.156561\n",
      "Train [15, 1001 / 11524] loss: 0.061\n",
      "01:38:29.657792\n",
      "Train [15, 1201 / 11524] loss: 0.061\n",
      "01:39:19.942142\n",
      "Train [15, 1401 / 11524] loss: 0.061\n",
      "01:40:10.247414\n",
      "Train [15, 1601 / 11524] loss: 0.061\n",
      "01:41:00.527121\n",
      "Train [15, 1801 / 11524] loss: 0.061\n",
      "01:41:50.718173\n",
      "Train [15, 2001 / 11524] loss: 0.061\n",
      "01:42:40.972118\n",
      "Train [15, 2201 / 11524] loss: 0.061\n",
      "01:43:31.271270\n",
      "Train [15, 2401 / 11524] loss: 0.061\n",
      "01:44:21.456815\n",
      "Train [15, 2601 / 11524] loss: 0.061\n",
      "01:45:11.615711\n",
      "Train [15, 2801 / 11524] loss: 0.061\n",
      "01:46:01.853120\n",
      "Train [15, 3001 / 11524] loss: 0.061\n",
      "01:46:52.037204\n",
      "Train [15, 3201 / 11524] loss: 0.061\n",
      "01:47:42.255625\n",
      "Train [15, 3401 / 11524] loss: 0.061\n",
      "01:48:32.475754\n",
      "Train [15, 3601 / 11524] loss: 0.061\n",
      "01:49:22.674161\n",
      "Train [15, 3801 / 11524] loss: 0.061\n",
      "01:50:12.874333\n",
      "Train [15, 4001 / 11524] loss: 0.061\n",
      "01:51:03.113159\n",
      "Train [15, 4201 / 11524] loss: 0.061\n",
      "01:51:53.319570\n",
      "Train [15, 4401 / 11524] loss: 0.061\n",
      "01:52:43.489522\n",
      "Train [15, 4601 / 11524] loss: 0.061\n",
      "01:53:33.882685\n",
      "Train [15, 4801 / 11524] loss: 0.061\n",
      "01:54:24.091740\n",
      "Train [15, 5001 / 11524] loss: 0.061\n",
      "01:55:14.501938\n",
      "Train [15, 5201 / 11524] loss: 0.061\n",
      "01:56:04.740545\n",
      "Train [15, 5401 / 11524] loss: 0.061\n",
      "01:56:54.981132\n",
      "Train [15, 5601 / 11524] loss: 0.061\n",
      "01:57:45.259973\n",
      "Train [15, 5801 / 11524] loss: 0.061\n",
      "01:58:35.634916\n",
      "Train [15, 6001 / 11524] loss: 0.061\n",
      "01:59:26.017130\n",
      "Train [15, 6201 / 11524] loss: 0.061\n",
      "02:00:16.290867\n",
      "Train [15, 6401 / 11524] loss: 0.061\n",
      "02:01:06.785708\n",
      "Train [15, 6601 / 11524] loss: 0.061\n",
      "02:01:56.959895\n",
      "Train [15, 6801 / 11524] loss: 0.061\n",
      "02:02:47.211563\n",
      "Train [15, 7001 / 11524] loss: 0.061\n",
      "02:03:37.620260\n",
      "Train [15, 7201 / 11524] loss: 0.061\n",
      "02:04:27.714711\n",
      "Train [15, 7401 / 11524] loss: 0.061\n",
      "02:05:17.941889\n",
      "Train [15, 7601 / 11524] loss: 0.061\n",
      "02:06:08.143346\n",
      "Train [15, 7801 / 11524] loss: 0.061\n",
      "02:06:58.383853\n",
      "Train [15, 8001 / 11524] loss: 0.061\n",
      "02:07:48.723525\n",
      "Train [15, 8201 / 11524] loss: 0.061\n",
      "02:08:39.000747\n",
      "Train [15, 8401 / 11524] loss: 0.061\n",
      "02:09:29.259882\n",
      "Train [15, 8601 / 11524] loss: 0.061\n",
      "02:10:19.471504\n",
      "Train [15, 8801 / 11524] loss: 0.061\n",
      "02:11:09.724400\n",
      "Train [15, 9001 / 11524] loss: 0.061\n",
      "02:12:00.120165\n",
      "Train [15, 9201 / 11524] loss: 0.061\n",
      "02:12:50.378713\n",
      "Train [15, 9401 / 11524] loss: 0.061\n",
      "02:13:40.691209\n",
      "Train [15, 9601 / 11524] loss: 0.061\n",
      "02:14:30.861369\n",
      "Train [15, 9801 / 11524] loss: 0.061\n",
      "02:15:21.116388\n",
      "Train [15, 10001 / 11524] loss: 0.061\n",
      "02:16:11.441113\n",
      "Train [15, 10201 / 11524] loss: 0.061\n",
      "02:17:01.859171\n",
      "Train [15, 10401 / 11524] loss: 0.061\n",
      "02:17:52.184678\n",
      "Train [15, 10601 / 11524] loss: 0.061\n",
      "02:18:42.504268\n",
      "Train [15, 10801 / 11524] loss: 0.061\n",
      "02:19:32.988913\n",
      "Train [15, 11001 / 11524] loss: 0.061\n",
      "02:20:23.256105\n",
      "Train [15, 11201 / 11524] loss: 0.061\n",
      "02:21:13.502108\n",
      "Train [15, 11401 / 11524] loss: 0.061\n",
      "02:22:03.893905\n",
      "Validate [15,     1 /   641 ] loss: 0.062\n",
      "02:22:37.312262\n",
      "Test set: Accuracy: 50.58%\n",
      "Train [16, 1 / 11524] loss: 0.000\n",
      "02:37:38.690071\n",
      "Train [16, 201 / 11524] loss: 0.061\n",
      "02:38:28.200227\n",
      "Train [16, 401 / 11524] loss: 0.061\n",
      "02:39:18.302041\n",
      "Train [16, 601 / 11524] loss: 0.061\n",
      "02:40:08.586683\n",
      "Train [16, 801 / 11524] loss: 0.061\n",
      "02:40:59.039395\n",
      "Train [16, 1001 / 11524] loss: 0.061\n",
      "02:41:49.721286\n",
      "Train [16, 1201 / 11524] loss: 0.061\n",
      "02:42:40.127028\n",
      "Train [16, 1401 / 11524] loss: 0.061\n",
      "02:43:30.546732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train [16, 1601 / 11524] loss: 0.061\n",
      "02:44:20.983084\n",
      "Train [16, 1801 / 11524] loss: 0.061\n",
      "02:45:11.351503\n",
      "Train [16, 2001 / 11524] loss: 0.061\n",
      "02:46:01.755185\n",
      "Train [16, 2201 / 11524] loss: 0.061\n",
      "02:46:52.177772\n",
      "Train [16, 2401 / 11524] loss: 0.061\n",
      "02:47:42.456094\n",
      "Train [16, 2601 / 11524] loss: 0.061\n",
      "02:48:32.786641\n",
      "Train [16, 2801 / 11524] loss: 0.061\n",
      "02:49:23.089250\n",
      "Train [16, 3001 / 11524] loss: 0.061\n",
      "02:50:13.355179\n",
      "Train [16, 3201 / 11524] loss: 0.061\n",
      "02:51:03.599033\n",
      "Train [16, 3401 / 11524] loss: 0.061\n",
      "02:51:53.865056\n",
      "Train [16, 3601 / 11524] loss: 0.061\n",
      "02:52:44.150338\n",
      "Train [16, 3801 / 11524] loss: 0.061\n",
      "02:53:34.745940\n",
      "Train [16, 4001 / 11524] loss: 0.061\n",
      "02:54:25.059163\n",
      "Train [16, 4201 / 11524] loss: 0.061\n",
      "02:55:15.269965\n",
      "Train [16, 4401 / 11524] loss: 0.061\n",
      "02:56:05.650346\n",
      "Train [16, 4601 / 11524] loss: 0.061\n",
      "02:56:55.948562\n",
      "Train [16, 4801 / 11524] loss: 0.061\n",
      "02:57:46.211027\n",
      "Train [16, 5001 / 11524] loss: 0.061\n",
      "02:58:36.578187\n",
      "Train [16, 5201 / 11524] loss: 0.061\n",
      "02:59:26.905502\n",
      "Train [16, 5401 / 11524] loss: 0.061\n",
      "03:00:17.263514\n",
      "Train [16, 5601 / 11524] loss: 0.061\n",
      "03:01:07.633965\n",
      "Train [16, 5801 / 11524] loss: 0.061\n",
      "03:01:58.020898\n",
      "Train [16, 6001 / 11524] loss: 0.061\n",
      "03:02:48.218486\n",
      "Train [16, 6201 / 11524] loss: 0.061\n",
      "03:03:38.510252\n",
      "Train [16, 6401 / 11524] loss: 0.061\n",
      "03:04:29.024512\n",
      "Train [16, 6601 / 11524] loss: 0.061\n",
      "03:05:19.218837\n",
      "Train [16, 6801 / 11524] loss: 0.061\n",
      "03:06:09.737388\n",
      "Train [16, 7001 / 11524] loss: 0.061\n",
      "03:07:00.178412\n",
      "Train [16, 7201 / 11524] loss: 0.061\n",
      "03:07:50.604744\n",
      "Train [16, 7401 / 11524] loss: 0.061\n",
      "03:08:41.104813\n",
      "Train [16, 7601 / 11524] loss: 0.061\n",
      "03:09:31.546473\n",
      "Train [16, 7801 / 11524] loss: 0.061\n",
      "03:10:21.901287\n",
      "Train [16, 8001 / 11524] loss: 0.061\n",
      "03:11:12.230195\n",
      "Train [16, 8201 / 11524] loss: 0.061\n",
      "03:12:02.569314\n",
      "Train [16, 8401 / 11524] loss: 0.061\n",
      "03:12:52.945941\n",
      "Train [16, 8601 / 11524] loss: 0.061\n",
      "03:13:43.321575\n",
      "Train [16, 8801 / 11524] loss: 0.061\n",
      "03:14:33.759632\n",
      "Train [16, 9001 / 11524] loss: 0.061\n",
      "03:15:24.177135\n",
      "Train [16, 9201 / 11524] loss: 0.061\n",
      "03:16:14.664478\n",
      "Train [16, 9401 / 11524] loss: 0.061\n",
      "03:17:05.084919\n",
      "Train [16, 9601 / 11524] loss: 0.061\n",
      "03:17:55.502096\n",
      "Train [16, 9801 / 11524] loss: 0.061\n",
      "03:18:45.936295\n",
      "Train [16, 10001 / 11524] loss: 0.061\n",
      "03:19:36.454378\n",
      "Train [16, 10201 / 11524] loss: 0.061\n",
      "03:20:26.784143\n",
      "Train [16, 10401 / 11524] loss: 0.061\n",
      "03:21:17.214193\n",
      "Train [16, 10601 / 11524] loss: 0.061\n",
      "03:22:07.360166\n",
      "Train [16, 10801 / 11524] loss: 0.061\n",
      "03:22:57.783465\n",
      "Train [16, 11001 / 11524] loss: 0.061\n",
      "03:23:48.090028\n",
      "Train [16, 11201 / 11524] loss: 0.061\n",
      "03:24:38.480610\n",
      "Train [16, 11401 / 11524] loss: 0.061\n",
      "03:25:28.683334\n",
      "Validate [16,     1 /   641 ] loss: 0.063\n",
      "03:26:02.368514\n",
      "Test set: Accuracy: 41.85%\n",
      "Train [17, 1 / 11524] loss: 0.000\n",
      "03:41:12.289708\n",
      "Train [17, 201 / 11524] loss: 0.061\n",
      "03:42:01.848068\n",
      "Train [17, 401 / 11524] loss: 0.061\n",
      "03:42:51.924806\n",
      "Train [17, 601 / 11524] loss: 0.061\n",
      "03:43:42.272527\n",
      "Train [17, 801 / 11524] loss: 0.061\n",
      "03:44:33.018336\n",
      "Train [17, 1001 / 11524] loss: 0.061\n",
      "03:45:23.715037\n",
      "Train [17, 1201 / 11524] loss: 0.061\n",
      "03:46:14.366546\n",
      "Train [17, 1401 / 11524] loss: 0.061\n",
      "03:47:05.159638\n",
      "Train [17, 1601 / 11524] loss: 0.061\n",
      "03:47:55.694171\n",
      "Train [17, 1801 / 11524] loss: 0.061\n",
      "03:48:46.275791\n",
      "Train [17, 2001 / 11524] loss: 0.061\n",
      "03:49:36.805709\n",
      "Train [17, 2201 / 11524] loss: 0.061\n",
      "03:50:27.316459\n",
      "Train [17, 2401 / 11524] loss: 0.061\n",
      "03:51:17.779913\n",
      "Train [17, 2601 / 11524] loss: 0.061\n",
      "03:52:08.234583\n",
      "Train [17, 2801 / 11524] loss: 0.061\n",
      "03:52:58.856768\n",
      "Train [17, 3001 / 11524] loss: 0.061\n",
      "03:53:49.381874\n",
      "Train [17, 3201 / 11524] loss: 0.061\n",
      "03:54:39.912339\n",
      "Train [17, 3401 / 11524] loss: 0.061\n",
      "03:55:30.484988\n",
      "Train [17, 3601 / 11524] loss: 0.061\n",
      "03:56:21.015812\n",
      "Train [17, 3801 / 11524] loss: 0.061\n",
      "03:57:11.396191\n",
      "Train [17, 4001 / 11524] loss: 0.061\n",
      "03:58:01.890816\n",
      "Train [17, 4201 / 11524] loss: 0.061\n",
      "03:58:52.360150\n",
      "Train [17, 4401 / 11524] loss: 0.061\n",
      "03:59:42.775105\n",
      "Train [17, 4601 / 11524] loss: 0.061\n",
      "04:00:33.425429\n",
      "Train [17, 4801 / 11524] loss: 0.061\n",
      "04:01:23.880230\n",
      "Train [17, 5001 / 11524] loss: 0.061\n",
      "04:02:14.380602\n",
      "Train [17, 5201 / 11524] loss: 0.061\n",
      "04:03:04.839789\n",
      "Train [17, 5401 / 11524] loss: 0.061\n",
      "04:03:55.208747\n",
      "Train [17, 5601 / 11524] loss: 0.061\n",
      "04:04:45.689818\n",
      "Train [17, 5801 / 11524] loss: 0.061\n",
      "04:05:36.147224\n",
      "Train [17, 6001 / 11524] loss: 0.061\n",
      "04:06:26.731046\n",
      "Train [17, 6201 / 11524] loss: 0.061\n",
      "04:07:17.308101\n",
      "Train [17, 6401 / 11524] loss: 0.061\n",
      "04:08:07.716298\n",
      "Train [17, 6601 / 11524] loss: 0.061\n",
      "04:08:58.236435\n",
      "Train [17, 6801 / 11524] loss: 0.061\n",
      "04:09:48.764165\n",
      "Train [17, 7001 / 11524] loss: 0.061\n",
      "04:10:39.213907\n",
      "Train [17, 7201 / 11524] loss: 0.061\n",
      "04:11:29.732982\n",
      "Train [17, 7401 / 11524] loss: 0.061\n",
      "04:12:20.473150\n",
      "Train [17, 7601 / 11524] loss: 0.061\n",
      "04:13:10.946062\n",
      "Train [17, 7801 / 11524] loss: 0.061\n",
      "04:14:01.386469\n",
      "Train [17, 8001 / 11524] loss: 0.061\n",
      "04:14:51.832975\n",
      "Train [17, 8201 / 11524] loss: 0.061\n",
      "04:15:42.284980\n",
      "Train [17, 8401 / 11524] loss: 0.061\n",
      "04:16:32.709235\n",
      "Train [17, 8601 / 11524] loss: 0.061\n",
      "04:17:23.171923\n",
      "Train [17, 8801 / 11524] loss: 0.061\n",
      "04:18:13.607386\n",
      "Train [17, 9001 / 11524] loss: 0.061\n",
      "04:19:04.160108\n",
      "Train [17, 9201 / 11524] loss: 0.061\n",
      "04:19:54.707492\n",
      "Train [17, 9401 / 11524] loss: 0.061\n",
      "04:20:45.293708\n",
      "Train [17, 9601 / 11524] loss: 0.061\n",
      "04:21:35.570859\n",
      "Train [17, 9801 / 11524] loss: 0.061\n",
      "04:22:26.061850\n",
      "Train [17, 10001 / 11524] loss: 0.061\n",
      "04:23:16.551506\n",
      "Train [17, 10201 / 11524] loss: 0.061\n",
      "04:24:06.901735\n",
      "Train [17, 10401 / 11524] loss: 0.061\n",
      "04:24:57.426021\n",
      "Train [17, 10601 / 11524] loss: 0.061\n",
      "04:25:48.019430\n",
      "Train [17, 10801 / 11524] loss: 0.061\n",
      "04:26:38.690128\n",
      "Train [17, 11001 / 11524] loss: 0.061\n",
      "04:27:29.187103\n",
      "Train [17, 11201 / 11524] loss: 0.061\n",
      "04:28:19.734446\n",
      "Train [17, 11401 / 11524] loss: 0.061\n",
      "04:29:10.308200\n",
      "Validate [17,     1 /   641 ] loss: 0.060\n",
      "04:29:43.850880\n",
      "Test set: Accuracy: 32.23%\n",
      "Train [18, 1 / 11524] loss: 0.000\n",
      "04:44:47.997909\n",
      "Train [18, 201 / 11524] loss: 0.061\n",
      "04:45:37.349565\n",
      "Train [18, 401 / 11524] loss: 0.061\n",
      "04:46:27.222444\n",
      "Train [18, 601 / 11524] loss: 0.061\n",
      "04:47:17.615431\n",
      "Train [18, 801 / 11524] loss: 0.061\n",
      "04:48:07.967858\n",
      "Train [18, 1001 / 11524] loss: 0.061\n",
      "04:48:58.485595\n",
      "Train [18, 1201 / 11524] loss: 0.061\n",
      "04:49:48.835551\n",
      "Train [18, 1401 / 11524] loss: 0.061\n",
      "04:50:39.216901\n",
      "Train [18, 1601 / 11524] loss: 0.061\n",
      "04:51:29.547036\n",
      "Train [18, 1801 / 11524] loss: 0.061\n",
      "04:52:19.874911\n",
      "Train [18, 2001 / 11524] loss: 0.061\n",
      "04:53:10.285256\n",
      "Train [18, 2201 / 11524] loss: 0.061\n",
      "04:54:00.609696\n",
      "Train [18, 2401 / 11524] loss: 0.061\n",
      "04:54:50.983017\n",
      "Train [18, 2601 / 11524] loss: 0.061\n",
      "04:55:41.111845\n",
      "Train [18, 2801 / 11524] loss: 0.061\n",
      "04:56:31.423490\n",
      "Train [18, 3001 / 11524] loss: 0.061\n",
      "04:57:21.640306\n",
      "Train [18, 3201 / 11524] loss: 0.061\n",
      "04:58:11.974809\n",
      "Train [18, 3401 / 11524] loss: 0.061\n",
      "04:59:02.239619\n",
      "Train [18, 3601 / 11524] loss: 0.061\n",
      "04:59:52.501809\n",
      "Train [18, 3801 / 11524] loss: 0.061\n",
      "05:00:42.738619\n",
      "Train [18, 4001 / 11524] loss: 0.061\n",
      "05:01:33.047690\n",
      "Train [18, 4201 / 11524] loss: 0.061\n",
      "05:02:23.394855\n",
      "Train [18, 4401 / 11524] loss: 0.061\n",
      "05:03:13.583370\n",
      "Train [18, 4601 / 11524] loss: 0.061\n",
      "05:04:03.822234\n",
      "Train [18, 4801 / 11524] loss: 0.061\n",
      "05:04:54.171793\n",
      "Train [18, 5001 / 11524] loss: 0.061\n",
      "05:05:44.443479\n",
      "Train [18, 5201 / 11524] loss: 0.061\n",
      "05:06:34.768569\n",
      "Train [18, 5401 / 11524] loss: 0.061\n",
      "05:07:25.106569\n",
      "Train [18, 5601 / 11524] loss: 0.061\n",
      "05:08:15.514853\n",
      "Train [18, 5801 / 11524] loss: 0.061\n",
      "05:09:05.868254\n",
      "Train [18, 6001 / 11524] loss: 0.061\n",
      "05:09:56.218272\n",
      "Train [18, 6201 / 11524] loss: 0.061\n",
      "05:10:46.555438\n",
      "Train [18, 6401 / 11524] loss: 0.061\n",
      "05:11:36.904280\n",
      "Train [18, 6601 / 11524] loss: 0.061\n",
      "05:12:27.247956\n",
      "Train [18, 6801 / 11524] loss: 0.061\n",
      "05:13:17.673218\n",
      "Train [18, 7001 / 11524] loss: 0.061\n",
      "05:14:08.047026\n",
      "Train [18, 7201 / 11524] loss: 0.061\n",
      "05:14:58.495737\n",
      "Train [18, 7401 / 11524] loss: 0.061\n",
      "05:15:48.791615\n",
      "Train [18, 7601 / 11524] loss: 0.061\n",
      "05:16:39.026763\n",
      "Train [18, 7801 / 11524] loss: 0.061\n",
      "05:17:29.420227\n",
      "Train [18, 8001 / 11524] loss: 0.061\n",
      "05:18:19.826410\n",
      "Train [18, 8201 / 11524] loss: 0.061\n",
      "05:19:10.107052\n",
      "Train [18, 8401 / 11524] loss: 0.061\n",
      "05:20:00.381002\n",
      "Train [18, 8601 / 11524] loss: 0.061\n",
      "05:20:50.660348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train [18, 8801 / 11524] loss: 0.061\n",
      "05:21:41.095630\n",
      "Train [18, 9001 / 11524] loss: 0.061\n",
      "05:22:31.404704\n",
      "Train [18, 9201 / 11524] loss: 0.061\n",
      "05:23:21.729958\n",
      "Train [18, 9401 / 11524] loss: 0.061\n",
      "05:24:12.085691\n",
      "Train [18, 9601 / 11524] loss: 0.061\n",
      "05:25:02.384442\n",
      "Train [18, 9801 / 11524] loss: 0.061\n",
      "05:25:52.705434\n",
      "Train [18, 10001 / 11524] loss: 0.061\n",
      "05:26:43.062100\n",
      "Train [18, 10201 / 11524] loss: 0.061\n",
      "05:27:33.392562\n",
      "Train [18, 10401 / 11524] loss: 0.061\n",
      "05:28:23.671329\n",
      "Train [18, 10601 / 11524] loss: 0.061\n",
      "05:29:14.006896\n",
      "Train [18, 10801 / 11524] loss: 0.061\n",
      "05:30:04.256415\n",
      "Train [18, 11001 / 11524] loss: 0.061\n",
      "05:30:54.512705\n",
      "Train [18, 11201 / 11524] loss: 0.061\n",
      "05:31:44.941563\n",
      "Train [18, 11401 / 11524] loss: 0.061\n",
      "05:32:35.480686\n",
      "Validate [18,     1 /   641 ] loss: 0.062\n",
      "05:33:09.710300\n",
      "Test set: Accuracy: 41.40%\n",
      "Train [19, 1 / 11524] loss: 0.000\n",
      "05:48:17.115811\n",
      "Train [19, 201 / 11524] loss: 0.061\n",
      "05:49:06.572617\n",
      "Train [19, 401 / 11524] loss: 0.061\n",
      "05:49:56.554131\n",
      "Train [19, 601 / 11524] loss: 0.061\n",
      "05:50:46.873025\n",
      "Train [19, 801 / 11524] loss: 0.061\n",
      "05:51:37.453671\n",
      "Train [19, 1001 / 11524] loss: 0.061\n",
      "05:52:28.128199\n",
      "Train [19, 1201 / 11524] loss: 0.061\n",
      "05:53:19.084621\n",
      "Train [19, 1401 / 11524] loss: 0.061\n",
      "05:54:09.600265\n",
      "Train [19, 1601 / 11524] loss: 0.061\n",
      "05:55:00.185153\n",
      "Train [19, 1801 / 11524] loss: 0.061\n",
      "05:55:50.625615\n",
      "Train [19, 2001 / 11524] loss: 0.061\n",
      "05:56:41.096382\n",
      "Train [19, 2201 / 11524] loss: 0.061\n",
      "05:57:31.738908\n",
      "Train [19, 2401 / 11524] loss: 0.061\n",
      "05:58:22.429029\n",
      "Train [19, 2601 / 11524] loss: 0.061\n",
      "05:59:12.939047\n",
      "Train [19, 2801 / 11524] loss: 0.061\n",
      "06:00:03.270370\n",
      "Train [19, 3001 / 11524] loss: 0.061\n",
      "06:00:53.849142\n",
      "Train [19, 3201 / 11524] loss: 0.061\n",
      "06:01:44.416899\n",
      "Train [19, 3401 / 11524] loss: 0.061\n",
      "06:02:34.812513\n",
      "Train [19, 3601 / 11524] loss: 0.061\n",
      "06:03:25.371069\n",
      "Train [19, 3801 / 11524] loss: 0.061\n",
      "06:04:15.816356\n",
      "Train [19, 4001 / 11524] loss: 0.061\n",
      "06:05:06.392941\n",
      "Train [19, 4201 / 11524] loss: 0.061\n",
      "06:05:56.743396\n",
      "Train [19, 4401 / 11524] loss: 0.061\n",
      "06:06:47.364993\n",
      "Train [19, 4601 / 11524] loss: 0.061\n",
      "06:07:37.791689\n",
      "Train [19, 4801 / 11524] loss: 0.061\n",
      "06:08:28.141503\n",
      "Train [19, 5001 / 11524] loss: 0.061\n",
      "06:09:18.641041\n",
      "Train [19, 5201 / 11524] loss: 0.061\n",
      "06:10:09.197873\n",
      "Train [19, 5401 / 11524] loss: 0.061\n",
      "06:10:59.836397\n",
      "Train [19, 5601 / 11524] loss: 0.061\n",
      "06:11:50.291661\n",
      "Train [19, 5801 / 11524] loss: 0.061\n",
      "06:12:40.765104\n",
      "Train [19, 6001 / 11524] loss: 0.061\n",
      "06:13:31.196248\n",
      "Train [19, 6201 / 11524] loss: 0.061\n",
      "06:14:21.863548\n",
      "Train [19, 6401 / 11524] loss: 0.061\n",
      "06:15:12.428016\n",
      "Train [19, 6601 / 11524] loss: 0.061\n",
      "06:16:02.887494\n",
      "Train [19, 6801 / 11524] loss: 0.061\n",
      "06:16:53.426239\n",
      "Train [19, 7001 / 11524] loss: 0.061\n",
      "06:17:44.049387\n",
      "Train [19, 7201 / 11524] loss: 0.061\n",
      "06:18:34.708970\n",
      "Train [19, 7401 / 11524] loss: 0.061\n",
      "06:19:25.033058\n",
      "Train [19, 7601 / 11524] loss: 0.061\n",
      "06:20:15.511091\n",
      "Train [19, 7801 / 11524] loss: 0.061\n",
      "06:21:06.065987\n",
      "Train [19, 8001 / 11524] loss: 0.061\n",
      "06:21:56.486490\n",
      "Train [19, 8201 / 11524] loss: 0.061\n",
      "06:22:46.908277\n",
      "Train [19, 8401 / 11524] loss: 0.061\n",
      "06:23:37.361701\n",
      "Train [19, 8601 / 11524] loss: 0.061\n",
      "06:24:27.810020\n",
      "Train [19, 8801 / 11524] loss: 0.061\n",
      "06:25:18.319782\n",
      "Train [19, 9001 / 11524] loss: 0.061\n",
      "06:26:08.828904\n",
      "Train [19, 9201 / 11524] loss: 0.061\n",
      "06:26:59.205517\n",
      "Train [19, 9401 / 11524] loss: 0.061\n",
      "06:27:49.749251\n",
      "Train [19, 9601 / 11524] loss: 0.061\n",
      "06:28:40.114403\n",
      "Train [19, 9801 / 11524] loss: 0.061\n",
      "06:29:30.537618\n",
      "Train [19, 10001 / 11524] loss: 0.061\n",
      "06:30:21.007762\n",
      "Train [19, 10201 / 11524] loss: 0.061\n",
      "06:31:11.524583\n",
      "Train [19, 10401 / 11524] loss: 0.061\n",
      "06:32:02.019740\n",
      "Train [19, 10601 / 11524] loss: 0.061\n",
      "06:32:52.556990\n",
      "Train [19, 10801 / 11524] loss: 0.061\n",
      "06:33:43.080220\n",
      "Train [19, 11001 / 11524] loss: 0.061\n",
      "06:34:33.566619\n",
      "Train [19, 11201 / 11524] loss: 0.061\n",
      "06:35:24.055388\n",
      "Train [19, 11401 / 11524] loss: 0.061\n",
      "06:36:14.448905\n",
      "Validate [19,     1 /   641 ] loss: 0.061\n",
      "06:36:48.494201\n",
      "Test set: Accuracy: 44.89%\n",
      "Train [20, 1 / 11524] loss: 0.000\n",
      "06:51:59.484866\n",
      "Train [20, 201 / 11524] loss: 0.061\n",
      "06:52:49.110993\n",
      "Train [20, 401 / 11524] loss: 0.061\n",
      "06:53:39.012433\n",
      "Train [20, 601 / 11524] loss: 0.061\n",
      "06:54:29.364772\n",
      "Train [20, 801 / 11524] loss: 0.061\n",
      "06:55:19.833731\n",
      "Train [20, 1001 / 11524] loss: 0.061\n",
      "06:56:10.357658\n",
      "Train [20, 1201 / 11524] loss: 0.061\n",
      "06:57:00.768075\n",
      "Train [20, 1401 / 11524] loss: 0.061\n",
      "06:57:51.390529\n",
      "Train [20, 1601 / 11524] loss: 0.061\n",
      "06:58:41.761829\n",
      "Train [20, 1801 / 11524] loss: 0.061\n",
      "06:59:32.308434\n",
      "Train [20, 2001 / 11524] loss: 0.061\n",
      "07:00:22.910542\n",
      "Train [20, 2201 / 11524] loss: 0.061\n",
      "07:01:13.451013\n",
      "Train [20, 2401 / 11524] loss: 0.061\n",
      "07:02:03.820637\n",
      "Train [20, 2601 / 11524] loss: 0.061\n",
      "07:02:54.257497\n",
      "Train [20, 2801 / 11524] loss: 0.061\n",
      "07:03:44.805658\n",
      "Train [20, 3001 / 11524] loss: 0.061\n",
      "07:04:35.237577\n",
      "Train [20, 3201 / 11524] loss: 0.061\n",
      "07:05:25.738414\n",
      "Train [20, 3401 / 11524] loss: 0.061\n",
      "07:06:16.199931\n",
      "Train [20, 3601 / 11524] loss: 0.061\n",
      "07:07:06.653422\n",
      "Train [20, 3801 / 11524] loss: 0.061\n",
      "07:07:57.061628\n",
      "Train [20, 4001 / 11524] loss: 0.061\n",
      "07:08:47.425271\n",
      "Train [20, 4201 / 11524] loss: 0.061\n",
      "07:09:38.205301\n",
      "Train [20, 4401 / 11524] loss: 0.061\n",
      "07:10:28.704002\n",
      "Train [20, 4601 / 11524] loss: 0.061\n",
      "07:11:19.082202\n",
      "Train [20, 4801 / 11524] loss: 0.061\n",
      "07:12:09.650347\n",
      "Train [20, 5001 / 11524] loss: 0.061\n",
      "07:13:00.100500\n",
      "Train [20, 5201 / 11524] loss: 0.061\n",
      "07:13:50.469578\n",
      "Train [20, 5401 / 11524] loss: 0.061\n",
      "07:14:40.897185\n",
      "Train [20, 5601 / 11524] loss: 0.061\n",
      "07:15:31.373194\n",
      "Train [20, 5801 / 11524] loss: 0.061\n",
      "07:16:21.787043\n",
      "Train [20, 6001 / 11524] loss: 0.061\n",
      "07:17:12.157580\n",
      "Train [20, 6201 / 11524] loss: 0.061\n",
      "07:18:02.578226\n",
      "Train [20, 6401 / 11524] loss: 0.061\n",
      "07:18:52.946955\n",
      "Train [20, 6601 / 11524] loss: 0.061\n",
      "07:19:43.478691\n",
      "Train [20, 6801 / 11524] loss: 0.061\n",
      "07:20:34.021636\n",
      "Train [20, 7001 / 11524] loss: 0.061\n",
      "07:21:24.523337\n",
      "Train [20, 7201 / 11524] loss: 0.061\n",
      "07:22:14.871352\n",
      "Train [20, 7401 / 11524] loss: 0.061\n",
      "07:23:05.251202\n",
      "Train [20, 7601 / 11524] loss: 0.061\n",
      "07:23:55.703805\n",
      "Train [20, 7801 / 11524] loss: 0.061\n",
      "07:24:46.155902\n",
      "Train [20, 8001 / 11524] loss: 0.061\n",
      "07:25:36.598084\n",
      "Train [20, 8201 / 11524] loss: 0.061\n",
      "07:26:26.914383\n",
      "Train [20, 8401 / 11524] loss: 0.061\n",
      "07:27:17.530429\n",
      "Train [20, 8601 / 11524] loss: 0.061\n",
      "07:28:08.061344\n",
      "Train [20, 8801 / 11524] loss: 0.061\n",
      "07:28:58.608557\n",
      "Train [20, 9001 / 11524] loss: 0.061\n",
      "07:29:49.079111\n",
      "Train [20, 9201 / 11524] loss: 0.061\n",
      "07:30:39.502468\n",
      "Train [20, 9401 / 11524] loss: 0.061\n",
      "07:31:29.927051\n",
      "Train [20, 9601 / 11524] loss: 0.061\n",
      "07:32:20.441566\n",
      "Train [20, 9801 / 11524] loss: 0.061\n",
      "07:33:10.977000\n",
      "Train [20, 10001 / 11524] loss: 0.061\n",
      "07:34:01.468705\n",
      "Train [20, 10201 / 11524] loss: 0.061\n",
      "07:34:51.897276\n",
      "Train [20, 10401 / 11524] loss: 0.061\n",
      "07:35:42.394429\n",
      "Train [20, 10601 / 11524] loss: 0.061\n",
      "07:36:32.812712\n",
      "Train [20, 10801 / 11524] loss: 0.061\n",
      "07:37:23.278522\n",
      "Train [20, 11001 / 11524] loss: 0.061\n",
      "07:38:13.732653\n",
      "Train [20, 11201 / 11524] loss: 0.061\n",
      "07:39:04.370908\n",
      "Train [20, 11401 / 11524] loss: 0.061\n",
      "07:39:54.895808\n",
      "Validate [20,     1 /   641 ] loss: 0.059\n",
      "07:40:28.760201\n",
      "Test set: Accuracy: 46.91%\n",
      "Train [21, 1 / 11524] loss: 0.000\n",
      "07:55:41.157405\n",
      "Train [21, 201 / 11524] loss: 0.061\n",
      "07:56:30.721964\n",
      "Train [21, 401 / 11524] loss: 0.061\n",
      "07:57:20.423343\n",
      "Train [21, 601 / 11524] loss: 0.061\n",
      "07:58:10.658777\n",
      "Train [21, 801 / 11524] loss: 0.061\n",
      "07:59:00.940530\n",
      "Train [21, 1001 / 11524] loss: 0.061\n",
      "07:59:51.306413\n",
      "Train [21, 1201 / 11524] loss: 0.061\n",
      "08:00:41.643137\n",
      "Train [21, 1401 / 11524] loss: 0.061\n",
      "08:01:31.967879\n",
      "Train [21, 1601 / 11524] loss: 0.061\n",
      "08:02:22.327717\n",
      "Train [21, 1801 / 11524] loss: 0.061\n",
      "08:03:12.597782\n",
      "Train [21, 2001 / 11524] loss: 0.061\n",
      "08:04:02.786022\n",
      "Train [21, 2201 / 11524] loss: 0.061\n",
      "08:04:53.042248\n",
      "Train [21, 2401 / 11524] loss: 0.061\n",
      "08:05:43.270671\n",
      "Train [21, 2601 / 11524] loss: 0.061\n",
      "08:06:33.633315\n",
      "Train [21, 2801 / 11524] loss: 0.061\n",
      "08:07:23.904694\n",
      "Train [21, 3001 / 11524] loss: 0.061\n",
      "08:08:14.059056\n",
      "Train [21, 3201 / 11524] loss: 0.061\n",
      "08:09:04.360108\n",
      "Train [21, 3401 / 11524] loss: 0.061\n",
      "08:09:54.758041\n",
      "Train [21, 3601 / 11524] loss: 0.061\n",
      "08:10:44.970029\n",
      "Train [21, 3801 / 11524] loss: 0.061\n",
      "08:11:35.326854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train [21, 4001 / 11524] loss: 0.061\n",
      "08:12:25.714452\n",
      "Train [21, 4201 / 11524] loss: 0.061\n",
      "08:13:15.906522\n",
      "Train [21, 4401 / 11524] loss: 0.061\n",
      "08:14:06.162416\n",
      "Train [21, 4601 / 11524] loss: 0.061\n",
      "08:14:56.459866\n",
      "Train [21, 4801 / 11524] loss: 0.061\n",
      "08:15:46.861430\n",
      "Train [21, 5001 / 11524] loss: 0.061\n",
      "08:16:37.067964\n",
      "Train [21, 5201 / 11524] loss: 0.061\n",
      "08:17:27.412776\n",
      "Train [21, 5401 / 11524] loss: 0.061\n",
      "08:18:17.693731\n",
      "Train [21, 5601 / 11524] loss: 0.061\n",
      "08:19:08.136014\n",
      "Train [21, 5801 / 11524] loss: 0.061\n",
      "08:19:58.445559\n",
      "Train [21, 6001 / 11524] loss: 0.061\n",
      "08:20:48.715119\n",
      "Train [21, 6201 / 11524] loss: 0.061\n",
      "08:21:38.899760\n",
      "Train [21, 6401 / 11524] loss: 0.061\n",
      "08:22:29.158585\n",
      "Train [21, 6601 / 11524] loss: 0.061\n",
      "08:23:19.415139\n",
      "Train [21, 6801 / 11524] loss: 0.061\n",
      "08:24:09.755773\n",
      "Train [21, 7001 / 11524] loss: 0.061\n",
      "08:25:00.147058\n",
      "Train [21, 7201 / 11524] loss: 0.061\n",
      "08:25:50.439155\n",
      "Train [21, 7401 / 11524] loss: 0.061\n",
      "08:26:40.790802\n",
      "Train [21, 7601 / 11524] loss: 0.061\n",
      "08:27:31.039604\n",
      "Train [21, 7801 / 11524] loss: 0.061\n",
      "08:28:21.357817\n",
      "Train [21, 8001 / 11524] loss: 0.061\n",
      "08:29:11.718698\n",
      "Train [21, 8201 / 11524] loss: 0.061\n",
      "08:30:01.980375\n",
      "Train [21, 8401 / 11524] loss: 0.061\n",
      "08:30:52.265521\n",
      "Train [21, 8601 / 11524] loss: 0.061\n",
      "08:31:42.593945\n",
      "Train [21, 8801 / 11524] loss: 0.061\n",
      "08:32:32.839875\n",
      "Train [21, 9001 / 11524] loss: 0.061\n",
      "08:33:23.171355\n",
      "Train [21, 9201 / 11524] loss: 0.061\n",
      "08:34:13.444171\n",
      "Train [21, 9401 / 11524] loss: 0.061\n",
      "08:35:03.779461\n",
      "Train [21, 9601 / 11524] loss: 0.061\n",
      "08:35:54.036972\n",
      "Train [21, 9801 / 11524] loss: 0.061\n",
      "08:36:44.346540\n",
      "Train [21, 10001 / 11524] loss: 0.061\n",
      "08:37:34.681168\n",
      "Train [21, 10201 / 11524] loss: 0.061\n",
      "08:38:24.896344\n",
      "Train [21, 10401 / 11524] loss: 0.061\n",
      "08:39:15.047800\n",
      "Train [21, 10601 / 11524] loss: 0.061\n",
      "08:40:05.513949\n",
      "Train [21, 10801 / 11524] loss: 0.061\n",
      "08:40:55.813648\n",
      "Train [21, 11001 / 11524] loss: 0.061\n",
      "08:41:46.242581\n",
      "Train [21, 11201 / 11524] loss: 0.061\n",
      "08:42:36.606264\n",
      "Train [21, 11401 / 11524] loss: 0.061\n",
      "08:43:27.137447\n",
      "Validate [21,     1 /   641 ] loss: 0.061\n",
      "08:44:01.008873\n",
      "Test set: Accuracy: 47.24%\n",
      "Train [22, 1 / 11524] loss: 0.000\n",
      "08:59:04.261972\n",
      "Train [22, 201 / 11524] loss: 0.061\n",
      "08:59:53.290342\n",
      "Train [22, 401 / 11524] loss: 0.061\n",
      "09:00:42.909885\n",
      "Train [22, 601 / 11524] loss: 0.061\n",
      "09:01:32.736673\n",
      "Train [22, 801 / 11524] loss: 0.061\n",
      "09:02:22.721050\n",
      "Train [22, 1001 / 11524] loss: 0.061\n",
      "09:03:12.522173\n",
      "Train [22, 1201 / 11524] loss: 0.061\n",
      "09:04:02.483047\n",
      "Train [22, 1401 / 11524] loss: 0.061\n",
      "09:04:52.362253\n",
      "Train [22, 1601 / 11524] loss: 0.061\n",
      "09:05:42.021620\n",
      "Train [22, 1801 / 11524] loss: 0.061\n",
      "09:06:31.700090\n",
      "Train [22, 2001 / 11524] loss: 0.061\n",
      "09:07:21.252443\n",
      "Train [22, 2201 / 11524] loss: 0.061\n",
      "09:08:10.980035\n",
      "Train [22, 2401 / 11524] loss: 0.061\n",
      "09:09:00.484534\n",
      "Train [22, 2601 / 11524] loss: 0.061\n",
      "09:09:50.069132\n",
      "Train [22, 2801 / 11524] loss: 0.061\n",
      "09:10:39.404807\n",
      "Train [22, 3001 / 11524] loss: 0.061\n",
      "09:11:29.018737\n",
      "Train [22, 3201 / 11524] loss: 0.061\n",
      "09:12:18.538519\n",
      "Train [22, 3401 / 11524] loss: 0.061\n",
      "09:13:08.094265\n",
      "Train [22, 3601 / 11524] loss: 0.061\n",
      "09:13:57.320559\n",
      "Train [22, 3801 / 11524] loss: 0.061\n",
      "09:14:46.905348\n",
      "Train [22, 4001 / 11524] loss: 0.061\n",
      "09:15:36.168479\n",
      "Train [22, 4201 / 11524] loss: 0.061\n",
      "09:16:25.505152\n",
      "Train [22, 4401 / 11524] loss: 0.061\n",
      "09:17:14.856923\n",
      "Train [22, 4601 / 11524] loss: 0.061\n",
      "09:18:04.213927\n",
      "Train [22, 4801 / 11524] loss: 0.061\n",
      "09:18:53.695896\n",
      "Train [22, 5001 / 11524] loss: 0.061\n",
      "09:19:43.093135\n",
      "Train [22, 5201 / 11524] loss: 0.061\n",
      "09:20:32.321820\n",
      "Train [22, 5401 / 11524] loss: 0.061\n",
      "09:21:21.491406\n",
      "Train [22, 5601 / 11524] loss: 0.061\n",
      "09:22:10.738941\n",
      "Train [22, 5801 / 11524] loss: 0.061\n",
      "09:23:00.166842\n",
      "Train [22, 6001 / 11524] loss: 0.061\n",
      "09:23:49.471756\n",
      "Train [22, 6201 / 11524] loss: 0.061\n",
      "09:24:38.838619\n",
      "Train [22, 6401 / 11524] loss: 0.061\n",
      "09:25:28.165680\n",
      "Train [22, 6601 / 11524] loss: 0.061\n",
      "09:26:17.517476\n",
      "Train [22, 6801 / 11524] loss: 0.061\n",
      "09:27:06.860357\n",
      "Train [22, 7001 / 11524] loss: 0.061\n",
      "09:27:56.186001\n",
      "Train [22, 7201 / 11524] loss: 0.061\n",
      "09:28:45.387328\n",
      "Train [22, 7401 / 11524] loss: 0.061\n",
      "09:29:34.776054\n",
      "Train [22, 7601 / 11524] loss: 0.061\n",
      "09:30:23.849612\n",
      "Train [22, 7801 / 11524] loss: 0.061\n",
      "09:31:13.186340\n",
      "Train [22, 8001 / 11524] loss: 0.061\n",
      "09:32:02.379849\n",
      "Train [22, 8201 / 11524] loss: 0.061\n",
      "09:32:51.765750\n",
      "Train [22, 8401 / 11524] loss: 0.061\n",
      "09:33:41.057364\n",
      "Train [22, 8601 / 11524] loss: 0.061\n",
      "09:34:30.510202\n",
      "Train [22, 8801 / 11524] loss: 0.061\n",
      "09:35:19.809228\n",
      "Train [22, 9001 / 11524] loss: 0.061\n",
      "09:36:09.066375\n",
      "Train [22, 9201 / 11524] loss: 0.061\n",
      "09:36:58.451777\n",
      "Train [22, 9401 / 11524] loss: 0.061\n",
      "09:37:47.813749\n",
      "Train [22, 9601 / 11524] loss: 0.061\n",
      "09:38:37.062867\n",
      "Train [22, 9801 / 11524] loss: 0.061\n",
      "09:39:26.319426\n",
      "Train [22, 10001 / 11524] loss: 0.061\n",
      "09:40:15.670199\n",
      "Train [22, 10201 / 11524] loss: 0.061\n",
      "09:41:04.749416\n",
      "Train [22, 10401 / 11524] loss: 0.061\n",
      "09:41:54.080424\n",
      "Train [22, 10601 / 11524] loss: 0.061\n",
      "09:42:43.579839\n",
      "Train [22, 10801 / 11524] loss: 0.061\n",
      "09:43:32.697854\n",
      "Train [22, 11001 / 11524] loss: 0.061\n",
      "09:44:22.221474\n",
      "Train [22, 11201 / 11524] loss: 0.061\n",
      "09:45:11.668654\n",
      "Train [22, 11401 / 11524] loss: 0.061\n",
      "09:46:00.888563\n",
      "Validate [22,     1 /   641 ] loss: 0.064\n",
      "09:46:33.549634\n",
      "Test set: Accuracy: 39.12%\n",
      "Train [23, 1 / 11524] loss: 0.000\n",
      "10:01:45.787842\n",
      "Train [23, 201 / 11524] loss: 0.061\n",
      "10:02:34.960435\n",
      "Train [23, 401 / 11524] loss: 0.061\n",
      "10:03:24.375601\n",
      "Train [23, 601 / 11524] loss: 0.061\n",
      "10:04:14.009245\n",
      "Train [23, 801 / 11524] loss: 0.061\n",
      "10:05:03.783016\n",
      "Train [23, 1001 / 11524] loss: 0.061\n",
      "10:05:53.504180\n",
      "Train [23, 1201 / 11524] loss: 0.061\n",
      "10:06:43.341095\n",
      "Train [23, 1401 / 11524] loss: 0.061\n",
      "10:07:32.974739\n",
      "Train [23, 1601 / 11524] loss: 0.061\n",
      "10:08:22.612021\n",
      "Train [23, 1801 / 11524] loss: 0.061\n",
      "10:09:12.257930\n",
      "Train [23, 2001 / 11524] loss: 0.061\n",
      "10:10:01.820013\n",
      "Train [23, 2201 / 11524] loss: 0.061\n",
      "10:10:51.367108\n",
      "Train [23, 2401 / 11524] loss: 0.061\n",
      "10:11:40.954840\n",
      "Train [23, 2601 / 11524] loss: 0.061\n",
      "10:12:30.464201\n",
      "Train [23, 2801 / 11524] loss: 0.061\n",
      "10:13:19.814347\n",
      "Train [23, 3001 / 11524] loss: 0.061\n",
      "10:14:09.324104\n",
      "Train [23, 3201 / 11524] loss: 0.061\n",
      "10:14:58.772390\n",
      "Train [23, 3401 / 11524] loss: 0.061\n",
      "10:15:48.530625\n",
      "Train [23, 3601 / 11524] loss: 0.061\n",
      "10:16:38.023256\n",
      "Train [23, 3801 / 11524] loss: 0.061\n",
      "10:17:27.522570\n",
      "Train [23, 4001 / 11524] loss: 0.061\n",
      "10:18:16.960339\n",
      "Train [23, 4201 / 11524] loss: 0.061\n",
      "10:19:06.442979\n",
      "Train [23, 4401 / 11524] loss: 0.061\n",
      "10:19:55.941507\n",
      "Train [23, 4601 / 11524] loss: 0.061\n",
      "10:20:45.482671\n",
      "Train [23, 4801 / 11524] loss: 0.061\n",
      "10:21:34.964149\n",
      "Train [23, 5001 / 11524] loss: 0.061\n",
      "10:22:24.421780\n",
      "Train [23, 5201 / 11524] loss: 0.061\n",
      "10:23:13.940862\n",
      "Train [23, 5401 / 11524] loss: 0.061\n",
      "10:24:03.453231\n",
      "Train [23, 5601 / 11524] loss: 0.061\n",
      "10:24:53.053826\n",
      "Train [23, 5801 / 11524] loss: 0.061\n",
      "10:25:42.473128\n",
      "Train [23, 6001 / 11524] loss: 0.061\n",
      "10:26:31.832433\n",
      "Train [23, 6201 / 11524] loss: 0.061\n",
      "10:27:21.243669\n",
      "Train [23, 6401 / 11524] loss: 0.061\n",
      "10:28:10.627101\n",
      "Train [23, 6601 / 11524] loss: 0.061\n",
      "10:29:00.062309\n",
      "Train [23, 6801 / 11524] loss: 0.061\n",
      "10:29:49.542107\n",
      "Train [23, 7001 / 11524] loss: 0.061\n",
      "10:30:39.055911\n",
      "Train [23, 7201 / 11524] loss: 0.061\n",
      "10:31:28.641840\n",
      "Train [23, 7401 / 11524] loss: 0.061\n",
      "10:32:17.955008\n",
      "Train [23, 7601 / 11524] loss: 0.061\n",
      "10:33:07.451717\n",
      "Train [23, 7801 / 11524] loss: 0.061\n",
      "10:33:56.888907\n",
      "Train [23, 8001 / 11524] loss: 0.061\n",
      "10:34:46.340588\n",
      "Train [23, 8201 / 11524] loss: 0.061\n",
      "10:35:35.926254\n",
      "Train [23, 8401 / 11524] loss: 0.061\n",
      "10:36:25.489652\n",
      "Train [23, 8601 / 11524] loss: 0.061\n",
      "10:37:14.828050\n",
      "Train [23, 8801 / 11524] loss: 0.061\n",
      "10:38:04.332727\n",
      "Train [23, 9001 / 11524] loss: 0.061\n",
      "10:38:53.842441\n",
      "Train [23, 9201 / 11524] loss: 0.061\n",
      "10:39:43.403066\n",
      "Train [23, 9401 / 11524] loss: 0.061\n",
      "10:40:32.931779\n",
      "Train [23, 9601 / 11524] loss: 0.061\n",
      "10:41:22.401768\n",
      "Train [23, 9801 / 11524] loss: 0.061\n",
      "10:42:11.805573\n",
      "Train [23, 10001 / 11524] loss: 0.061\n",
      "10:43:01.216498\n",
      "Train [23, 10201 / 11524] loss: 0.061\n",
      "10:43:50.717064\n",
      "Train [23, 10401 / 11524] loss: 0.061\n",
      "10:44:40.215797\n",
      "Train [23, 10601 / 11524] loss: 0.061\n",
      "10:45:29.695611\n",
      "Train [23, 10801 / 11524] loss: 0.061\n",
      "10:46:19.240314\n",
      "Train [23, 11001 / 11524] loss: 0.061\n",
      "10:47:08.826275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train [23, 11201 / 11524] loss: 0.061\n",
      "10:47:58.484239\n",
      "Train [23, 11401 / 11524] loss: 0.061\n",
      "10:48:48.022342\n",
      "Validate [23,     1 /   641 ] loss: 0.061\n",
      "10:49:21.612024\n",
      "Test set: Accuracy: 47.52%\n",
      "Train [24, 1 / 11524] loss: 0.000\n",
      "11:04:23.529839\n",
      "Train [24, 201 / 11524] loss: 0.061\n",
      "11:05:12.429221\n",
      "Train [24, 401 / 11524] loss: 0.061\n",
      "11:06:01.675718\n",
      "Train [24, 601 / 11524] loss: 0.061\n",
      "11:06:51.179672\n",
      "Train [24, 801 / 11524] loss: 0.061\n",
      "11:07:40.959614\n",
      "Train [24, 1001 / 11524] loss: 0.061\n",
      "11:08:30.710675\n",
      "Train [24, 1201 / 11524] loss: 0.061\n",
      "11:09:20.469027\n",
      "Train [24, 1401 / 11524] loss: 0.061\n",
      "11:10:10.077679\n",
      "Train [24, 1601 / 11524] loss: 0.061\n",
      "11:10:59.641712\n",
      "Train [24, 1801 / 11524] loss: 0.061\n",
      "11:11:49.226002\n",
      "Train [24, 2001 / 11524] loss: 0.061\n",
      "11:12:38.734367\n",
      "Train [24, 2201 / 11524] loss: 0.061\n",
      "11:13:28.245996\n",
      "Train [24, 2401 / 11524] loss: 0.061\n",
      "11:14:17.730200\n",
      "Train [24, 2601 / 11524] loss: 0.061\n",
      "11:15:07.119188\n",
      "Train [24, 2801 / 11524] loss: 0.061\n",
      "11:15:56.503022\n",
      "Train [24, 3001 / 11524] loss: 0.061\n",
      "11:16:46.081380\n",
      "Train [24, 3201 / 11524] loss: 0.061\n",
      "11:17:35.636712\n",
      "Train [24, 3401 / 11524] loss: 0.061\n",
      "11:18:25.018230\n",
      "Train [24, 3601 / 11524] loss: 0.061\n",
      "11:19:14.559976\n",
      "Train [24, 3801 / 11524] loss: 0.061\n",
      "11:20:03.995818\n",
      "Train [24, 4001 / 11524] loss: 0.061\n",
      "11:20:53.372734\n",
      "Train [24, 4201 / 11524] loss: 0.061\n",
      "11:21:42.966150\n",
      "Train [24, 4401 / 11524] loss: 0.061\n",
      "11:22:32.390070\n",
      "Train [24, 4601 / 11524] loss: 0.061\n",
      "11:23:21.911254\n",
      "Train [24, 4801 / 11524] loss: 0.061\n",
      "11:24:11.490178\n",
      "Train [24, 5001 / 11524] loss: 0.061\n",
      "11:25:00.883595\n",
      "Train [24, 5201 / 11524] loss: 0.061\n",
      "11:25:50.534738\n",
      "Train [24, 5401 / 11524] loss: 0.061\n",
      "11:26:39.866922\n",
      "Train [24, 5601 / 11524] loss: 0.061\n",
      "11:27:29.393056\n",
      "Train [24, 5801 / 11524] loss: 0.061\n",
      "11:28:18.813517\n",
      "Train [24, 6001 / 11524] loss: 0.061\n",
      "11:29:08.277124\n",
      "Train [24, 6201 / 11524] loss: 0.061\n",
      "11:29:57.769699\n",
      "Train [24, 6401 / 11524] loss: 0.061\n",
      "11:30:47.267986\n",
      "Train [24, 6601 / 11524] loss: 0.061\n",
      "11:31:36.867068\n",
      "Train [24, 6801 / 11524] loss: 0.061\n",
      "11:32:26.482183\n",
      "Train [24, 7001 / 11524] loss: 0.061\n",
      "11:33:15.966550\n",
      "Train [24, 7201 / 11524] loss: 0.061\n",
      "11:34:05.390851\n",
      "Train [24, 7401 / 11524] loss: 0.061\n",
      "11:34:54.922992\n",
      "Train [24, 7601 / 11524] loss: 0.061\n",
      "11:35:44.367212\n",
      "Train [24, 7801 / 11524] loss: 0.061\n",
      "11:36:33.934010\n",
      "Train [24, 8001 / 11524] loss: 0.061\n",
      "11:37:23.274596\n",
      "Train [24, 8201 / 11524] loss: 0.061\n",
      "11:38:12.698806\n",
      "Train [24, 8401 / 11524] loss: 0.061\n",
      "11:39:02.166168\n",
      "Train [24, 8601 / 11524] loss: 0.061\n",
      "11:39:51.583635\n",
      "Train [24, 8801 / 11524] loss: 0.061\n",
      "11:40:41.172394\n",
      "Train [24, 9001 / 11524] loss: 0.061\n",
      "11:41:30.535823\n",
      "Train [24, 9201 / 11524] loss: 0.061\n",
      "11:42:20.040159\n",
      "Train [24, 9401 / 11524] loss: 0.061\n",
      "11:43:09.420963\n",
      "Train [24, 9601 / 11524] loss: 0.061\n",
      "11:43:58.932116\n",
      "Train [24, 9801 / 11524] loss: 0.061\n",
      "11:44:48.446790\n",
      "Train [24, 10001 / 11524] loss: 0.061\n",
      "11:45:37.905277\n",
      "Train [24, 10201 / 11524] loss: 0.061\n",
      "11:46:27.436820\n",
      "Train [24, 10401 / 11524] loss: 0.061\n",
      "11:47:16.873428\n",
      "Train [24, 10601 / 11524] loss: 0.061\n",
      "11:48:06.426314\n",
      "Train [24, 10801 / 11524] loss: 0.061\n",
      "11:48:55.909295\n",
      "Train [24, 11001 / 11524] loss: 0.061\n",
      "11:49:45.379166\n",
      "Train [24, 11201 / 11524] loss: 0.061\n",
      "11:50:34.931337\n",
      "Train [24, 11401 / 11524] loss: 0.061\n",
      "11:51:24.446943\n",
      "Validate [24,     1 /   641 ] loss: 0.059\n",
      "11:51:58.138394\n",
      "Test set: Accuracy: 39.79%\n",
      "Train [25, 1 / 11524] loss: 0.000\n",
      "12:07:00.033570\n",
      "Train [25, 201 / 11524] loss: 0.061\n",
      "12:07:49.445518\n",
      "Train [25, 401 / 11524] loss: 0.061\n",
      "12:08:38.576778\n",
      "Train [25, 601 / 11524] loss: 0.061\n",
      "12:09:28.011856\n",
      "Train [25, 801 / 11524] loss: 0.061\n",
      "12:10:17.769977\n",
      "Train [25, 1001 / 11524] loss: 0.061\n",
      "12:11:07.494379\n",
      "Train [25, 1201 / 11524] loss: 0.061\n",
      "12:11:57.287043\n",
      "Train [25, 1401 / 11524] loss: 0.061\n",
      "12:12:47.028163\n",
      "Train [25, 1601 / 11524] loss: 0.061\n",
      "12:13:36.508434\n",
      "Train [25, 1801 / 11524] loss: 0.061\n",
      "12:14:25.994203\n",
      "Train [25, 2001 / 11524] loss: 0.061\n",
      "12:15:15.484403\n",
      "Train [25, 2201 / 11524] loss: 0.061\n",
      "12:16:04.892715\n",
      "Train [25, 2401 / 11524] loss: 0.061\n",
      "12:16:54.357926\n",
      "Train [25, 2601 / 11524] loss: 0.061\n",
      "12:17:43.808267\n",
      "Train [25, 2801 / 11524] loss: 0.061\n",
      "12:18:33.323143\n",
      "Train [25, 3001 / 11524] loss: 0.061\n",
      "12:19:22.679295\n",
      "Train [25, 3201 / 11524] loss: 0.061\n",
      "12:20:12.178738\n",
      "Train [25, 3401 / 11524] loss: 0.061\n",
      "12:21:01.715264\n",
      "Train [25, 3601 / 11524] loss: 0.061\n",
      "12:21:51.228235\n",
      "Train [25, 3801 / 11524] loss: 0.061\n",
      "12:22:40.708067\n",
      "Train [25, 4001 / 11524] loss: 0.061\n",
      "12:23:30.173720\n",
      "Train [25, 4201 / 11524] loss: 0.061\n",
      "12:24:19.612624\n",
      "Train [25, 4401 / 11524] loss: 0.061\n",
      "12:25:09.068005\n",
      "Train [25, 4601 / 11524] loss: 0.061\n",
      "12:25:58.585657\n",
      "Train [25, 4801 / 11524] loss: 0.061\n",
      "12:26:48.157241\n",
      "Train [25, 5001 / 11524] loss: 0.061\n",
      "12:27:37.648741\n",
      "Train [25, 5201 / 11524] loss: 0.061\n",
      "12:28:27.073168\n",
      "Train [25, 5401 / 11524] loss: 0.061\n",
      "12:29:16.510732\n",
      "Train [25, 5601 / 11524] loss: 0.061\n",
      "12:30:06.049672\n",
      "Train [25, 5801 / 11524] loss: 0.061\n",
      "12:30:55.398383\n",
      "Train [25, 6001 / 11524] loss: 0.061\n",
      "12:31:44.788876\n",
      "Train [25, 6201 / 11524] loss: 0.061\n",
      "12:32:34.179145\n",
      "Train [25, 6401 / 11524] loss: 0.061\n",
      "12:33:23.612070\n",
      "Train [25, 6601 / 11524] loss: 0.061\n",
      "12:34:12.963044\n",
      "Train [25, 6801 / 11524] loss: 0.061\n",
      "12:35:02.383674\n",
      "Train [25, 7001 / 11524] loss: 0.061\n",
      "12:35:51.846074\n",
      "Train [25, 7201 / 11524] loss: 0.061\n",
      "12:36:41.442845\n",
      "Train [25, 7401 / 11524] loss: 0.061\n",
      "12:37:30.949980\n",
      "Train [25, 7601 / 11524] loss: 0.061\n",
      "12:38:20.293336\n",
      "Train [25, 7801 / 11524] loss: 0.061\n",
      "12:39:09.688788\n",
      "Train [25, 8001 / 11524] loss: 0.061\n",
      "12:39:59.264211\n",
      "Train [25, 8201 / 11524] loss: 0.061\n",
      "12:40:48.795016\n",
      "Train [25, 8401 / 11524] loss: 0.061\n",
      "12:41:38.271848\n",
      "Train [25, 8601 / 11524] loss: 0.061\n",
      "12:42:27.665673\n",
      "Train [25, 8801 / 11524] loss: 0.061\n",
      "12:43:17.083502\n",
      "Train [25, 9001 / 11524] loss: 0.061\n",
      "12:44:06.534516\n",
      "Train [25, 9201 / 11524] loss: 0.061\n",
      "12:44:55.956376\n",
      "Train [25, 9401 / 11524] loss: 0.061\n",
      "12:45:45.409230\n",
      "Train [25, 9601 / 11524] loss: 0.061\n",
      "12:46:34.780896\n",
      "Train [25, 9801 / 11524] loss: 0.061\n",
      "12:47:24.273567\n",
      "Train [25, 10001 / 11524] loss: 0.061\n",
      "12:48:13.776273\n",
      "Train [25, 10201 / 11524] loss: 0.061\n",
      "12:49:03.235964\n",
      "Train [25, 10401 / 11524] loss: 0.061\n",
      "12:49:52.780060\n",
      "Train [25, 10601 / 11524] loss: 0.061\n",
      "12:50:42.283589\n",
      "Train [25, 10801 / 11524] loss: 0.061\n",
      "12:51:31.833990\n",
      "Train [25, 11001 / 11524] loss: 0.061\n",
      "12:52:21.149742\n",
      "Train [25, 11201 / 11524] loss: 0.061\n",
      "12:53:10.514341\n",
      "Train [25, 11401 / 11524] loss: 0.061\n",
      "12:53:59.935158\n",
      "Validate [25,     1 /   641 ] loss: 0.062\n",
      "12:54:33.615632\n",
      "Test set: Accuracy: 44.39%\n"
     ]
    }
   ],
   "source": [
    "print('EPOCH >',epoch)\n",
    "for epoch in range(epoch, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    val_loss = validate(val_loader, model, criterion,optimizer, epoch)\n",
    "    \n",
    "    TestData(test_loader,model)\n",
    "    # remember best prec@1 and save checkpoint\n",
    "    is_best = val_loss < best_loss\n",
    "    best_loss = min(val_loss, best_loss)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec1': best_loss,\n",
    "    }, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 12.00 MiB (GPU 1; 7.79 GiB total capacity; 6.49 GiB already allocated; 21.38 MiB free; 6.60 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d12d5705a71a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         num_workers=workers, pin_memory=True)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mTestData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-5f1aafef8f5e>\u001b[0m in \u001b[0;36mTestData\u001b[0;34m(test_loader, model)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlocationClass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/JS/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/JS/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/JS/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(self, module, device_ids)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/JS/lib/python3.7/site-packages/torch/nn/parallel/replicate.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(network, devices, detach)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mparam_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mparam_copies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_coalesced_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mbuffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/JS/lib/python3.7/site-packages/torch/nn/parallel/replicate.py\u001b[0m in \u001b[0;36m_broadcast_coalesced_reshape\u001b[0;34m(tensors, devices, detach)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Use the autograd function to broadcast if not detach\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mtensor_copies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBroadcast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             return [tensor_copies[i:i + len(tensors)]\n\u001b[1;32m     72\u001b[0m                     for i in range(0, len(tensor_copies), len(tensors))]\n",
      "\u001b[0;32m~/anaconda3/envs/JS/lib/python3.7/site-packages/torch/nn/parallel/_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, target_gpus, *inputs)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_coalesced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mnon_differentiables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_requires_grad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/JS/lib/python3.7/site-packages/torch/cuda/comm.py\u001b[0m in \u001b[0;36mbroadcast_coalesced\u001b[0;34m(tensors, devices, buffer_size)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mcorresponding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \"\"\"\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_coalesced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 1; 7.79 GiB total capacity; 6.49 GiB already allocated; 21.38 MiB free; 6.60 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
